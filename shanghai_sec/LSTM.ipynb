{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, HashingVectorizer, TfidfTransformer,TfidfVectorizer\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv',encoding='utf-8')\n",
    "train= pd.read_csv('train.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(420464, 2)\n",
      "(32875, 2)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>diaryofagameaddict.com</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>espdesign.com.au</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>iamagameaddict.com</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kalantzis.net</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>slightlyoffcenter.net</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      url label\n",
       "0  diaryofagameaddict.com   bad\n",
       "1        espdesign.com.au   bad\n",
       "2      iamagameaddict.com   bad\n",
       "3           kalantzis.net   bad\n",
       "4   slightlyoffcenter.net   bad"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "good    344821\n",
       "bad      75643\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train.iloc[:,0]\n",
    "train_y = train.iloc[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    diaryofagameaddict.com\n",
       "1          espdesign.com.au\n",
       "2        iamagameaddict.com\n",
       "3             kalantzis.net\n",
       "4     slightlyoffcenter.net\n",
       "5          toddscarwash.com\n",
       "Name: url, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    bad\n",
       "1    bad\n",
       "2    bad\n",
       "3    bad\n",
       "4    bad\n",
       "5    bad\n",
       "Name: label, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y[: 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "lbl = LabelEncoder()\n",
    "train_y = lbl.fit_transform(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(344821,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y[train_y==1].shape # good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75643,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y[train_y==0].shape # bad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分词---法①"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lazycat.I', \"'m\", 'super', 'lying', 'man', ',', 'This', 'is', 'a', 'coooool', '#', 'dummysmiley', ':', ':', '-', ')', ':', '-P', '<', '3', 'and', 'some', 'arrows', '<', '>', '-', '>', '<', '--', '#', '@', '@', 'qq.com']\n",
      "33\n",
      "['lazycat.I', \"'m\", 'super', 'lying', 'man', ',', 'This', 'is', 'a', 'coooool', '#', 'dummysmiley', ':', ':', '-', ')', ':', '-P', '<', '3', 'and', 'some', 'arrows', '<', '>', '-', '>', '<', '--', '#', '@', '@', 'qq.com']\n",
      "33\n",
      "['lazycat', '.', \"I'm\", 'super', 'lying', 'man', ',', 'This', 'is', 'a', 'coooool', '#dummysmiley', ':', ':-)', ':-P', '<3', 'and', 'some', 'arrows', '<', '>', '->', '<--', '#', '@', '@qq', '.', 'com']\n",
      "28\n",
      "['lazycat', '.', \"I'm\", 'super', 'lying', 'man', ',', 'This', 'is', 'a', 'coool', '#dummysmiley', ':', ':-)', ':-P', '<3', 'and', 'some', 'arrows', '<', '>', '->', '<--', '#', '@', '@qq', '.', 'com']\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "sent = \"lazycat.I'm super lying man,This is a coooool #dummysmiley: :-) :-P <3 and some arrows < > -><--#@@qq.com\"\n",
    "print(nltk.word_tokenize(sent))#该方法要求被处理的字符串本身各个词语之间有空格，能处理如don't, they'll等缩写词的情况。\n",
    "print(len(nltk.word_tokenize(sent)))\n",
    "print(nltk.tokenize.word_tokenize(sent))#该方法要求被处理的字符串本身各个词语之间有空格，能处理如don't, they'll等缩写词的情况。\n",
    "print(len(nltk.tokenize.word_tokenize(sent)))\n",
    "print(nltk.tokenize.TweetTokenizer().tokenize(sent))#能够拆分无效用的标点符号\n",
    "print(len(nltk.tokenize.TweetTokenizer().tokenize(sent)))\n",
    "print(nltk.tokenize.TweetTokenizer(strip_handles=True, reduce_len = True).tokenize(sent))#当一个词中相同字符连续出现3次以上，就只保留3个。设置strip_handles = True会删去@xxx。\n",
    "print(len(nltk.tokenize.TweetTokenizer().tokenize(sent)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precessing_data(data):\n",
    "    word = nltk.word_tokenize(data)\n",
    "    return ' '.join(data)\n",
    "#func_1\n",
    "def change_x(data):\n",
    "    data = data.map(precessing_data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ===================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分词： 法②"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#先'/'再'-'再'.'再'com'\n",
    "def getTokens(input):\n",
    "    tokensBySlash = str(input.encode('utf-8')).split('/')\t#get tokens after splitting by slash\n",
    "    allTokens = []\n",
    "    for i in tokensBySlash:\n",
    "        tokens = str(i).split('-')\t#get tokens after splitting by dash\n",
    "        tokensByDot = []\n",
    "        for j in range(0,len(tokens)):\n",
    "            tempTokens = str(tokens[j]).split('.')\t#get tokens after splitting by dot\n",
    "            tokensByDot = tokensByDot + tempTokens\n",
    "        allTokens = allTokens + tokens + tokensByDot\n",
    "    allTokens = list(allTokens)#-remove_set--#remove redundant tokens\n",
    "    if 'com' in allTokens:\n",
    "        allTokens.remove('com')\t#removing .com since it occurs a lot of times and it should not be included in our features\n",
    "    return allTokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_data_2(list_data):\n",
    "    new_data = ''\n",
    "    for i in list_data:\n",
    "        words = nltk.tokenize.TweetTokenizer(strip_handles=False, reduce_len = True).tokenize(i)\n",
    "        temp = ' '.join(words)\n",
    "        new_data = new_data + ' '+temp\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"b'https:\", \"b'https:\", '', '', 'www.bilibili.com', 'www', 'bilibili', 'video', 'video', 'av4836703', 'av4836703', 'fuckme home workplace&&>::', '):', \"P<3@qq.com'\", 'fuckme home workplace&&>::', '):', 'P<3@qq', \"com'\"]\n",
      "18\n",
      " b'https : b'https :   www.bilibili.com www bilibili video video av4836703 av4836703 fuckme home workplace & & >:: ): P <3 @qq . com ' fuckme home workplace & & >:: ): P <3 @qq com '\n",
      "182\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "url_test = 'https://www.bilibili.com/video/av4836703/fuckme home workplace&&>::-):-P<3@qq.com'\n",
    "url_test = getTokens(url_test)\n",
    "print(url_test)\n",
    "print(len(url_test))\n",
    "\n",
    "url_test = preprocessing_data_2(url_test)\n",
    "print(url_test)\n",
    "print(len(url_test))\n",
    "#然后喂给Tfidf\n",
    "# vectorizer = TfidfVectorizer(tokenizer=getTokens)\t#get a vector for each url but use our customized tokenizer\n",
    "# X = vectorizer.fit_transform(corpus)\t#get the X vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_x(data):\n",
    "    data = getTokens(data)\n",
    "    data = preprocessing_data_2(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " b'https : b'https :   www.bilibili.com www bilibili video video av4836703 av4836703 ( fuck ) me home workplace & & >:: ): P <3 @qq . com ' ( fuck ) me home workplace & & >:: ): P <3 @qq com '\n"
     ]
    }
   ],
   "source": [
    "url_test = 'https://www.bilibili.com/video/av4836703/(fuck)me home workplace&&>::-):-P<3@qq.com'\n",
    "url_test = pipeline_x(url_test)\n",
    "print(url_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ==============================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 处理数据X\n",
    "思路：\n",
    "- 按规则分词 + 特殊标记(TweetTokenizer)分词\n",
    "- Tokenizer\n",
    "- 喂给模型Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_data = train_x.apply(lambda x:pipeline_x(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" b'diaryofagameaddict . com ' b'diaryofagameaddict com '\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " www.bilibili.com video ): com ' av4836703 b'https : fuckme home workplace & & >:: P <3 @qq www bilibili P <3 @qq . com '\n"
     ]
    }
   ],
   "source": [
    "content = ['', 'www.bilibili.com', 'video', '):', \"com '\", 'av4836703', \"b'https :\", 'fuckme home workplace & & >::', 'P <3 @qq', 'www', 'bilibili', \"P <3 @qq . com '\"]\n",
    "t = ' '.join(content)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre_dataa = []\n",
    "# num = 0\n",
    "# for i in pre_data:\n",
    "#     for j in i:\n",
    "#         pre_dataa.append(j)\n",
    "#         num = num + 1\n",
    "pre_dataa = []\n",
    "for i in pre_data:\n",
    "    temp = ' '.join(i)\n",
    "    pre_dataa.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "420464"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pre_dataa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" b'diaryofagameaddict . com ' b'diaryofagameaddict com '\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_data[0] #正确的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"  b ' d i a r y o f a g a m e a d d i c t   .   c o m   '   b ' d i a r y o f a g a m e a d d i c t   c o m   '\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_dataa[0]# 错误的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "420464\n",
      "420464\n"
     ]
    }
   ],
   "source": [
    "print(train.shape[0])\n",
    "print(pre_data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 439245 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "#处理文本为序列的整数列表，制作x，y\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "maxlen = 15\n",
    "training_sample = train.shape[0]\n",
    "#validation_samples = \n",
    "max_words = 10000\n",
    "#max_words个单词的文本转数值转换器\n",
    "tokenizer = Tokenizer(num_words=max_words, lower=False)\n",
    "tokenizer.fit_on_texts(pre_data)\n",
    "#将字符串转化为整数索引的列表\n",
    "sequences = tokenizer.texts_to_sequences(pre_data)#如果model=‘bianry’则是01表示\n",
    "#获得  字符：数字 的字典\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "#将列表转换为（samples，maxlen）的二维整数张量\n",
    "data = pad_sequences(sequences, maxlen=maxlen)#maxlen设置最大的序列长度，长于该长度的序列将会截短，短于该长度的序列将会填充"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# f=open('./word_index.pk','wb')\n",
    "# pickle.dump(word_index,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (420464, 15)\n",
      "Shape of label tensor: (420464,)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of data tensor:', data.shape)\n",
    "print('Shape of label tensor:', train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 91, 1, 91, 1]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#处理完原始的sequence预览\n",
    "sequences[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"'\": 1,\n",
       " 'com': 2,\n",
       " 'html': 3,\n",
       " 'org': 4,\n",
       " 'php': 5,\n",
       " 'htm': 6,\n",
       " 'index': 7,\n",
       " 'net': 8,\n",
       " '1': 9,\n",
       " 'wiki': 10,\n",
       " \"b'en\": 11,\n",
       " 'wikipedia': 12,\n",
       " '2011': 13,\n",
       " 'b': 14,\n",
       " 'ca': 15,\n",
       " 'aspx': 16,\n",
       " 'id': 17,\n",
       " 'the': 18,\n",
       " 'of': 19,\n",
       " 'v': 20,\n",
       " 'watch': 21,\n",
       " 'in': 22,\n",
       " \"b'youtube\": 23,\n",
       " 'news': 24,\n",
       " 'wp': 25,\n",
       " '2': 26,\n",
       " \"b'facebook\": 27,\n",
       " 'blogspot': 28,\n",
       " 'edu': 29,\n",
       " 'co': 30,\n",
       " 'en': 31,\n",
       " 'people': 32,\n",
       " 'and': 33,\n",
       " '2010': 34,\n",
       " 'c': 35,\n",
       " 'uk': 36,\n",
       " 'info': 37,\n",
       " 'yahoo': 38,\n",
       " 'a': 39,\n",
       " 'p': 40,\n",
       " 's': 41,\n",
       " 'login': 42,\n",
       " \"b'amazon\": 43,\n",
       " 'asp': 44,\n",
       " 'name': 45,\n",
       " '4': 46,\n",
       " 'content': 47,\n",
       " 'to': 48,\n",
       " '10': 49,\n",
       " 'dp': 50,\n",
       " 'fid': 51,\n",
       " '3': 52,\n",
       " 'page': 53,\n",
       " 'us': 54,\n",
       " '0': 55,\n",
       " '11': 56,\n",
       " 'topic': 57,\n",
       " 'view': 58,\n",
       " 'article': 59,\n",
       " 'directory': 60,\n",
       " 'pages': 61,\n",
       " '2009': 62,\n",
       " 'de': 63,\n",
       " '18': 64,\n",
       " \"b'imdb\": 65,\n",
       " 'n': 66,\n",
       " \"b'linkedin\": 67,\n",
       " 'includes': 68,\n",
       " 'pub': 69,\n",
       " 'search': 70,\n",
       " 'city': 71,\n",
       " 'images': 72,\n",
       " 'm': 73,\n",
       " 'cgi': 74,\n",
       " 'ru': 75,\n",
       " 'admin': 76,\n",
       " 'music': 77,\n",
       " 't': 78,\n",
       " 'gov': 79,\n",
       " 'br': 80,\n",
       " 'about': 81,\n",
       " 'montreal': 82,\n",
       " 'topics': 83,\n",
       " '8': 84,\n",
       " 'for': 85,\n",
       " '5': 86,\n",
       " 'new': 87,\n",
       " \"b'myspace\": 88,\n",
       " 'sports': 89,\n",
       " 'rand': 90,\n",
       " 'au': 91,\n",
       " '01': 92,\n",
       " 'cfm': 93,\n",
       " \"b'mylife\": 94,\n",
       " '09': 95,\n",
       " 'story': 96,\n",
       " '17742564': 97,\n",
       " '12': 98,\n",
       " \"b'answers\": 99,\n",
       " 'lyrics': 100,\n",
       " 'ancestry': 101,\n",
       " 'genealogy': 102,\n",
       " '08': 103,\n",
       " 'js': 104,\n",
       " 'on': 105,\n",
       " '6': 106,\n",
       " 'd': 107,\n",
       " 'biz': 108,\n",
       " '7': 109,\n",
       " 'q': 110,\n",
       " 'wordpress': 111,\n",
       " 'artist': 112,\n",
       " '2008': 113,\n",
       " \"b'www\": 114,\n",
       " 'football': 115,\n",
       " '06': 116,\n",
       " 'The': 117,\n",
       " 'shtml': 118,\n",
       " 'exe': 119,\n",
       " 'go': 120,\n",
       " 'at': 121,\n",
       " '05': 122,\n",
       " '07': 123,\n",
       " 'players': 124,\n",
       " 'doc': 125,\n",
       " 'player': 126,\n",
       " 'i': 127,\n",
       " 'articles': 128,\n",
       " 'l': 129,\n",
       " '04': 130,\n",
       " 'album': 131,\n",
       " \"b'manta\": 132,\n",
       " 'blog': 133,\n",
       " '03': 134,\n",
       " 'video': 135,\n",
       " 'kansas': 136,\n",
       " '9': 137,\n",
       " 'home': 138,\n",
       " '02': 139,\n",
       " '20': 140,\n",
       " '2C': 141,\n",
       " 'school': 142,\n",
       " 'title': 143,\n",
       " 'Montreal': 144,\n",
       " '123people': 145,\n",
       " 'by': 146,\n",
       " 'email': 147,\n",
       " 'it': 148,\n",
       " 'tag': 149,\n",
       " \"b'wn\": 150,\n",
       " 'team': 151,\n",
       " 'files': 152,\n",
       " 'list': 153,\n",
       " \"b'absoluteastronomy\": 154,\n",
       " 'company': 155,\n",
       " 'e': 156,\n",
       " 'film': 157,\n",
       " '42': 158,\n",
       " 'fav': 159,\n",
       " 'wikia': 160,\n",
       " 'rootsweb': 161,\n",
       " 'dropbox': 162,\n",
       " '29': 163,\n",
       " 'state': 164,\n",
       " \"b'pipl\": 165,\n",
       " 'photos': 166,\n",
       " 'season': 167,\n",
       " 'linkedin': 168,\n",
       " 'history': 169,\n",
       " 'question': 170,\n",
       " 'canada': 171,\n",
       " 'fr': 172,\n",
       " 'pl': 173,\n",
       " 'online': 174,\n",
       " '13InboxLight': 175,\n",
       " 'show': 176,\n",
       " 'with': 177,\n",
       " 'tv': 178,\n",
       " 'pid': 179,\n",
       " 'data': 180,\n",
       " 'www': 181,\n",
       " 'bin': 182,\n",
       " 'City': 183,\n",
       " 'file': 184,\n",
       " '24': 185,\n",
       " 'C3': 186,\n",
       " 'movie': 187,\n",
       " '12528996': 188,\n",
       " \"b'ca\": 189,\n",
       " 'profile': 190,\n",
       " 'films': 191,\n",
       " '2007': 192,\n",
       " 'bio': 193,\n",
       " 'nhl': 194,\n",
       " 'plugins': 195,\n",
       " 'basketball': 196,\n",
       " 'secure': 197,\n",
       " 'all': 198,\n",
       " 'is': 199,\n",
       " \"b'music\": 200,\n",
       " '27': 201,\n",
       " '28': 202,\n",
       " 'D': 203,\n",
       " 'dir': 204,\n",
       " 'f': 205,\n",
       " 'P': 206,\n",
       " 'gallery': 207,\n",
       " 'Quebec': 208,\n",
       " 'http': 209,\n",
       " \"b'twitter\": 210,\n",
       " 'Kansas': 211,\n",
       " 'jsp': 212,\n",
       " 'main': 213,\n",
       " \"b'people\": 214,\n",
       " '22': 215,\n",
       " 'john': 216,\n",
       " 'abuse': 217,\n",
       " '25': 218,\n",
       " 'Category': 219,\n",
       " 'forum': 220,\n",
       " 'review': 221,\n",
       " 'media': 222,\n",
       " 'archive': 223,\n",
       " 'from': 224,\n",
       " 'oakland': 225,\n",
       " 'showthread': 226,\n",
       " 'person': 227,\n",
       " 'reference': 228,\n",
       " 'vs': 229,\n",
       " 'qid': 230,\n",
       " 'obituaries': 231,\n",
       " \"b'genforum\": 232,\n",
       " \"b'spoke\": 233,\n",
       " 'answers': 234,\n",
       " 'artists': 235,\n",
       " 'movies': 236,\n",
       " '13': 237,\n",
       " 'css': 238,\n",
       " 'google': 239,\n",
       " 'stream': 240,\n",
       " 'r': 241,\n",
       " '14': 242,\n",
       " 'famouswhy': 243,\n",
       " 'st': 244,\n",
       " 'archives': 245,\n",
       " 'battle': 246,\n",
       " '80': 247,\n",
       " 'top': 248,\n",
       " 'category': 249,\n",
       " 'List': 250,\n",
       " 'gate': 251,\n",
       " 'college': 252,\n",
       " '21': 253,\n",
       " 'quebec': 254,\n",
       " 'celebrity': 255,\n",
       " 'reviews': 256,\n",
       " '26': 257,\n",
       " 'text': 258,\n",
       " 'qc': 259,\n",
       " \"b'uk\": 260,\n",
       " 'game': 261,\n",
       " 'inc': 262,\n",
       " 'site': 263,\n",
       " '15': 264,\n",
       " 'live': 265,\n",
       " \"b'baseball\": 266,\n",
       " 'high': 267,\n",
       " 'ID': 268,\n",
       " 'w': 269,\n",
       " '16': 270,\n",
       " 'docs': 271,\n",
       " 'world': 272,\n",
       " 'themes': 273,\n",
       " 'fm': 274,\n",
       " 'pictures': 275,\n",
       " 'browse': 276,\n",
       " 'county': 277,\n",
       " 'tickets': 278,\n",
       " \"b'ebay\": 279,\n",
       " 'od': 280,\n",
       " \"b'wiki\": 281,\n",
       " \"b'movies\": 282,\n",
       " 'web': 283,\n",
       " 'A': 284,\n",
       " 'Canada': 285,\n",
       " \"b'spokeo\": 286,\n",
       " 'db': 287,\n",
       " '91': 288,\n",
       " 'details': 289,\n",
       " 'John': 290,\n",
       " 'business': 291,\n",
       " 'teams': 292,\n",
       " 'default': 293,\n",
       " 'update': 294,\n",
       " 'celebrities': 295,\n",
       " 'Q': 296,\n",
       " \"b'yelp\": 297,\n",
       " '17': 298,\n",
       " 'forums': 299,\n",
       " '13InboxLightaspxn': 300,\n",
       " \"b'archive\": 301,\n",
       " 'document': 302,\n",
       " 'nfl': 303,\n",
       " '19': 304,\n",
       " 'download': 305,\n",
       " 'upload': 306,\n",
       " '2006': 307,\n",
       " 'national': 308,\n",
       " 'es': 309,\n",
       " 'New': 310,\n",
       " 'mlb': 311,\n",
       " 'products': 312,\n",
       " 'no': 313,\n",
       " '30': 314,\n",
       " 'cmd': 315,\n",
       " '23': 316,\n",
       " 'ro': 317,\n",
       " 'action': 318,\n",
       " 'obituary': 319,\n",
       " 'ii': 320,\n",
       " 'post': 321,\n",
       " 'actor': 322,\n",
       " 'product': 323,\n",
       " 'txt': 324,\n",
       " 'public': 325,\n",
       " 'United': 326,\n",
       " 'za': 327,\n",
       " 'records': 328,\n",
       " 'free': 329,\n",
       " 'me': 330,\n",
       " \"b'blog\": 331,\n",
       " 'la': 332,\n",
       " 'aspxn': 333,\n",
       " 'lang': 334,\n",
       " \"b'flickr\": 335,\n",
       " 'schools': 336,\n",
       " \"b'sports\": 337,\n",
       " 'be': 338,\n",
       " \"b'freebase\": 339,\n",
       " 'ref': 340,\n",
       " \"b'evri\": 341,\n",
       " 'detail': 342,\n",
       " 'app': 343,\n",
       " 'robert': 344,\n",
       " 'CA': 345,\n",
       " 'events': 346,\n",
       " 'david': 347,\n",
       " 'eu': 348,\n",
       " 'auth': 349,\n",
       " 'g': 350,\n",
       " 'hockey': 351,\n",
       " 'j': 352,\n",
       " 'group': 353,\n",
       " 'ie': 354,\n",
       " 'wright': 355,\n",
       " 'california': 356,\n",
       " \"b'freepages\": 357,\n",
       " \"b'mp\": 358,\n",
       " 'american': 359,\n",
       " 'family': 360,\n",
       " 'james': 361,\n",
       " 'cp': 362,\n",
       " 'paypal': 363,\n",
       " 'missouri': 364,\n",
       " 'do': 365,\n",
       " 'black': 366,\n",
       " 'espn': 367,\n",
       " \"b'articles\": 368,\n",
       " 'jean': 369,\n",
       " 'remax': 370,\n",
       " 'preview': 371,\n",
       " \"b'espn\": 372,\n",
       " 'local': 373,\n",
       " 'stats': 374,\n",
       " 'modules': 375,\n",
       " 'States': 376,\n",
       " 'san': 377,\n",
       " 'dispatch': 378,\n",
       " 'facebook': 379,\n",
       " 'videos': 380,\n",
       " 'o': 381,\n",
       " 'author': 382,\n",
       " 'user': 383,\n",
       " 'paul': 384,\n",
       " \"b'classmates\": 385,\n",
       " 'California': 386,\n",
       " 'entertainment': 387,\n",
       " \"b'whosdatedwho\": 388,\n",
       " 'thefreedictionary': 389,\n",
       " 'band': 390,\n",
       " 'song': 391,\n",
       " 'cup': 392,\n",
       " 'up': 393,\n",
       " 'star': 394,\n",
       " '31': 395,\n",
       " 'sch': 396,\n",
       " \"b'last\": 397,\n",
       " 'book': 398,\n",
       " \"b'local\": 399,\n",
       " \"b'legacy\": 400,\n",
       " 'information': 401,\n",
       " 'mail': 402,\n",
       " 'radio': 403,\n",
       " 'club': 404,\n",
       " 'books': 405,\n",
       " '2005': 406,\n",
       " 'biography': 407,\n",
       " 'you': 408,\n",
       " \"b'yellowpages\": 409,\n",
       " 'img': 410,\n",
       " \"b'encyclopedia\": 411,\n",
       " 'apple': 412,\n",
       " 'soccer': 413,\n",
       " 'library': 414,\n",
       " 'zip': 415,\n",
       " 'C': 416,\n",
       " 'blogs': 417,\n",
       " 'baseball': 418,\n",
       " 'userid': 419,\n",
       " 'nytimes': 420,\n",
       " 'nl': 421,\n",
       " 'art': 422,\n",
       " 'cc': 423,\n",
       " 'components': 424,\n",
       " 'usa': 425,\n",
       " 'thread': 426,\n",
       " 'tpx': 427,\n",
       " 'American': 428,\n",
       " 'h': 429,\n",
       " 'Oakland': 430,\n",
       " 'read': 431,\n",
       " 'tripod': 432,\n",
       " 'dr': 433,\n",
       " 'School': 434,\n",
       " 'S': 435,\n",
       " 'system': 436,\n",
       " 'users': 437,\n",
       " 'djvu': 438,\n",
       " 'cat': 439,\n",
       " \"b'tvguide\": 440,\n",
       " \"b'docstoc\": 441,\n",
       " 'my': 442,\n",
       " 'schedule': 443,\n",
       " \"b'dictionary\": 444,\n",
       " 'language': 445,\n",
       " 'hotel': 446,\n",
       " 'cn': 447,\n",
       " 'photo': 448,\n",
       " \"b'rottentomatoes\": 449,\n",
       " 'eng': 450,\n",
       " 'd3': 451,\n",
       " 'community': 452,\n",
       " 'Canadian': 453,\n",
       " 'league': 454,\n",
       " 'nwww': 455,\n",
       " \"b'blogs\": 456,\n",
       " 'results': 457,\n",
       " 'mo': 458,\n",
       " 'US': 459,\n",
       " 'research': 460,\n",
       " 'State': 461,\n",
       " \"b'veromi\": 462,\n",
       " 'QC': 463,\n",
       " \"b'scribd\": 464,\n",
       " 'albums': 465,\n",
       " 'bookmark': 466,\n",
       " '192': 467,\n",
       " 'cl': 468,\n",
       " 'Product': 469,\n",
       " 'alibaba': 470,\n",
       " 'x': 471,\n",
       " 'releases': 472,\n",
       " '239': 473,\n",
       " 'msn': 474,\n",
       " \"b'tv\": 475,\n",
       " 'big': 476,\n",
       " '6892': 477,\n",
       " 'william': 478,\n",
       " 'best': 479,\n",
       " 'St': 480,\n",
       " 'cnn': 481,\n",
       " 'libraries': 482,\n",
       " 'y': 483,\n",
       " 'canadian': 484,\n",
       " 'jobs': 485,\n",
       " 'nkw': 486,\n",
       " 'County': 487,\n",
       " 'english': 488,\n",
       " 'baskbl': 489,\n",
       " 'hotels': 490,\n",
       " 'what': 491,\n",
       " 'Jean': 492,\n",
       " 'how': 493,\n",
       " \"b'duckduckgo\": 494,\n",
       " 'L': 495,\n",
       " 'house': 496,\n",
       " 'aol': 497,\n",
       " \"b'zoominfo\": 498,\n",
       " 'services': 499,\n",
       " 'type': 500,\n",
       " 'states': 501,\n",
       " '27s': 502,\n",
       " \"b'tripadvisor\": 503,\n",
       " 'first': 504,\n",
       " 'travel': 505,\n",
       " 'work': 506,\n",
       " 'Robert': 507,\n",
       " 'k': 508,\n",
       " 'James': 509,\n",
       " 'day': 510,\n",
       " 'series': 511,\n",
       " 'as': 512,\n",
       " 'tags': 513,\n",
       " 'time': 514,\n",
       " 'png': 515,\n",
       " 'true': 516,\n",
       " 'year': 517,\n",
       " '2004': 518,\n",
       " \"b'english\": 519,\n",
       " 'jpg': 520,\n",
       " 'JeHFUq': 521,\n",
       " \"b'fanbase\": 522,\n",
       " 'UserID': 523,\n",
       " 'ncaa': 524,\n",
       " 'service': 525,\n",
       " \"b'rootsweb\": 526,\n",
       " 'websc': 527,\n",
       " 'charles': 528,\n",
       " 'https': 529,\n",
       " 'profiles': 530,\n",
       " 'UTF': 531,\n",
       " 'gr': 532,\n",
       " 'William': 533,\n",
       " 'M': 534,\n",
       " \"b'news\": 535,\n",
       " '50': 536,\n",
       " 'op': 537,\n",
       " 'u': 538,\n",
       " 'account': 539,\n",
       " 'Charles': 540,\n",
       " '3D': 541,\n",
       " 'press': 542,\n",
       " 'templates': 543,\n",
       " 'ar': 544,\n",
       " 'companies': 545,\n",
       " 'doctors': 546,\n",
       " 'real': 547,\n",
       " 'life': 548,\n",
       " 'le': 549,\n",
       " 'contact': 550,\n",
       " 'michael': 551,\n",
       " 'rss': 552,\n",
       " 'event': 553,\n",
       " 'pdf': 554,\n",
       " 'one': 555,\n",
       " 'shows': 556,\n",
       " 'park': 557,\n",
       " 'united': 558,\n",
       " \"b'itunes\": 559,\n",
       " \"b'corporationwiki\": 560,\n",
       " 'ask': 561,\n",
       " '2016': 562,\n",
       " 'start': 563,\n",
       " 'university': 564,\n",
       " 'catalog': 565,\n",
       " \"b'flixster\": 566,\n",
       " 'center': 567,\n",
       " 'games': 568,\n",
       " 'ice': 569,\n",
       " 'session': 570,\n",
       " '2F': 571,\n",
       " 'sensagent': 572,\n",
       " 'Missouri': 573,\n",
       " 'Dr': 574,\n",
       " 'disney': 575,\n",
       " 'option': 576,\n",
       " 'ac': 577,\n",
       " 'actors': 578,\n",
       " 'News': 579,\n",
       " 'are': 580,\n",
       " 'roster': 581,\n",
       " \"b'reunion\": 582,\n",
       " 'law': 583,\n",
       " 'Paul': 584,\n",
       " 'image': 585,\n",
       " 'your': 586,\n",
       " '3A': 587,\n",
       " 'F': 588,\n",
       " 'cities': 589,\n",
       " 'cd': 590,\n",
       " 'sk': 591,\n",
       " 'nz': 592,\n",
       " 'west': 593,\n",
       " 'gc': 594,\n",
       " 'ohio': 595,\n",
       " 'turkcebilgi': 596,\n",
       " 'source': 597,\n",
       " \"b'forums\": 598,\n",
       " 'du': 599,\n",
       " 'David': 600,\n",
       " '00': 601,\n",
       " 'th': 602,\n",
       " 'Home': 603,\n",
       " 'atoz': 604,\n",
       " 'xhtml': 605,\n",
       " 'athletics': 606,\n",
       " \"b'nytimes\": 607,\n",
       " 'mod': 608,\n",
       " '93': 609,\n",
       " 'J': 610,\n",
       " 'shop': 611,\n",
       " 'celebs': 612,\n",
       " 'international': 613,\n",
       " 'mens': 614,\n",
       " 'power': 615,\n",
       " 'bill': 616,\n",
       " 'node': 617,\n",
       " '100': 618,\n",
       " 'gb': 619,\n",
       " 'Basketball': 620,\n",
       " 'mobile': 621,\n",
       " 'High': 622,\n",
       " 'torrents': 623,\n",
       " 'E2': 624,\n",
       " 'E': 625,\n",
       " 'full': 626,\n",
       " \"b'videosurf\": 627,\n",
       " 'item': 628,\n",
       " 'spec': 629,\n",
       " 'men': 630,\n",
       " 'indiana': 631,\n",
       " 'almanac': 632,\n",
       " 'stories': 633,\n",
       " 'B': 634,\n",
       " 'National': 635,\n",
       " \"b'montreal\": 636,\n",
       " '2000': 637,\n",
       " \"b'zimbio\": 638,\n",
       " 'url': 639,\n",
       " 'more': 640,\n",
       " 'DHL': 641,\n",
       " 'store': 642,\n",
       " 'University': 643,\n",
       " 'interview': 644,\n",
       " '37': 645,\n",
       " 'usatoday': 646,\n",
       " '32': 647,\n",
       " 'draft': 648,\n",
       " 'mcgill': 649,\n",
       " 'release': 650,\n",
       " 'tour': 651,\n",
       " 'World': 652,\n",
       " 'I': 653,\n",
       " 'torrent': 654,\n",
       " \"b'mxp\": 655,\n",
       " 'rel': 656,\n",
       " 'steve': 657,\n",
       " 'tom': 658,\n",
       " 'who': 659,\n",
       " 'R': 660,\n",
       " 'map': 661,\n",
       " '1252899642': 662,\n",
       " 'bus': 663,\n",
       " 'sid': 664,\n",
       " 'faculty': 665,\n",
       " 'love': 666,\n",
       " \"b'discogs\": 667,\n",
       " 'features': 668,\n",
       " 'bay': 669,\n",
       " 'North': 670,\n",
       " \"b'worthpoint\": 671,\n",
       " 'worthopedia': 672,\n",
       " '411': 673,\n",
       " 'arts': 674,\n",
       " 'Black': 675,\n",
       " '101': 676,\n",
       " '2002': 677,\n",
       " 'goldenmap': 678,\n",
       " 'network': 679,\n",
       " 'quotes': 680,\n",
       " 'country': 681,\n",
       " 'names': 682,\n",
       " \"b'city\": 683,\n",
       " 'out': 684,\n",
       " 'Itemid': 685,\n",
       " 'TV': 686,\n",
       " \"b'webmail\": 687,\n",
       " 'Inc': 688,\n",
       " 'or': 689,\n",
       " '2003': 690,\n",
       " 'bob': 691,\n",
       " '185': 692,\n",
       " 'man': 693,\n",
       " 'idx': 694,\n",
       " 'mp3': 695,\n",
       " 'craigslist': 696,\n",
       " \"b'songlyrics\": 697,\n",
       " 'check': 698,\n",
       " '2012': 699,\n",
       " 'york': 700,\n",
       " 'texas': 701,\n",
       " 'logs': 702,\n",
       " 'feed': 703,\n",
       " 'pierre': 704,\n",
       " \"b'boards\": 705,\n",
       " \"b'bleacherreport\": 706,\n",
       " \"b'content\": 707,\n",
       " 'League': 708,\n",
       " 'definition': 709,\n",
       " '40': 710,\n",
       " 'uploads': 711,\n",
       " 'an': 712,\n",
       " \"b'metrolyrics\": 713,\n",
       " 'board': 714,\n",
       " 'keyword': 715,\n",
       " 'saint': 716,\n",
       " \"b'icehockey\": 717,\n",
       " 'VJOXK0QWHtoGYDw': 718,\n",
       " \"b'familytreemaker\": 719,\n",
       " 'letter': 720,\n",
       " \"b'chacha\": 721,\n",
       " \"b'enotes\": 722,\n",
       " 'mhcable': 723,\n",
       " 'MO': 724,\n",
       " \"b'ehow\": 725,\n",
       " 'Family': 726,\n",
       " 'pics': 727,\n",
       " 'lib': 728,\n",
       " 'latimes': 729,\n",
       " 'Cup': 730,\n",
       " '2c': 731,\n",
       " 'frank': 732,\n",
       " 'office': 733,\n",
       " 'george': 734,\n",
       " 'thomas': 735,\n",
       " 'general': 736,\n",
       " 'old': 737,\n",
       " 'richard': 738,\n",
       " 'Saint': 739,\n",
       " 'What': 740,\n",
       " 'mx': 741,\n",
       " '20School': 742,\n",
       " 'hall': 743,\n",
       " \"b'thecanadianencyclopedia\": 744,\n",
       " '46': 745,\n",
       " 'north': 746,\n",
       " 'property': 747,\n",
       " 'dictionary': 748,\n",
       " 'guitar': 749,\n",
       " 'washington': 750,\n",
       " 'surnames': 751,\n",
       " \"b'lyricsmode\": 752,\n",
       " 'mark': 753,\n",
       " 'grand': 754,\n",
       " \"b'sportsillustrated\": 755,\n",
       " '66': 756,\n",
       " 'Params': 757,\n",
       " 'get': 758,\n",
       " 'sport': 759,\n",
       " 'whitepages': 760,\n",
       " '88': 761,\n",
       " '0001': 762,\n",
       " 'xyz': 763,\n",
       " '3Buf': 764,\n",
       " 'DB': 765,\n",
       " 'area': 766,\n",
       " \"b'canada\": 767,\n",
       " 'se': 768,\n",
       " '2001': 769,\n",
       " 'ufc': 770,\n",
       " 'San': 771,\n",
       " 'will': 772,\n",
       " 'administrator': 773,\n",
       " 'last': 774,\n",
       " 'verify': 775,\n",
       " 'ic': 776,\n",
       " 'mike': 777,\n",
       " \"b'web\": 778,\n",
       " \"b'names\": 779,\n",
       " 'al': 780,\n",
       " 'si': 781,\n",
       " 'excel': 782,\n",
       " 'ip': 783,\n",
       " 'lee': 784,\n",
       " '60': 785,\n",
       " 'los': 786,\n",
       " 'organization': 787,\n",
       " 'All': 788,\n",
       " 'lima': 789,\n",
       " 'igm': 790,\n",
       " '51': 791,\n",
       " '54': 792,\n",
       " 'report': 793,\n",
       " 'green': 794,\n",
       " '41': 795,\n",
       " \"b'vitals\": 796,\n",
       " \"b'fanpix\": 797,\n",
       " 'des': 798,\n",
       " 'dbml': 799,\n",
       " 'OEM': 800,\n",
       " \"b'jigsaw\": 801,\n",
       " 'log': 802,\n",
       " 'set': 803,\n",
       " 'his': 804,\n",
       " 'xc3': 805,\n",
       " 'webmail': 806,\n",
       " 'module': 807,\n",
       " 'codes': 808,\n",
       " 'Reviews': 809,\n",
       " 'scott': 810,\n",
       " 'viewtopic': 811,\n",
       " 'guide': 812,\n",
       " 'girl': 813,\n",
       " 'pw': 814,\n",
       " \"b'cbc\": 815,\n",
       " \"b'healthgrades\": 816,\n",
       " 'z': 817,\n",
       " '70': 818,\n",
       " 'awards': 819,\n",
       " 'finance': 820,\n",
       " 'George': 821,\n",
       " '2015': 822,\n",
       " 'joe': 823,\n",
       " 'History': 824,\n",
       " 'rh': 825,\n",
       " 'box': 826,\n",
       " 'Profile': 827,\n",
       " 'sale': 828,\n",
       " 'arashi': 829,\n",
       " 'Football': 830,\n",
       " \"b'usidentify\": 831,\n",
       " '34': 832,\n",
       " 'U': 833,\n",
       " 'Go': 834,\n",
       " 'ct': 835,\n",
       " 'PgNm': 836,\n",
       " 'hot': 837,\n",
       " \"b'hockeydb\": 838,\n",
       " 'blue': 839,\n",
       " 'peter': 840,\n",
       " 'members': 841,\n",
       " '95': 842,\n",
       " 'style': 843,\n",
       " 'Review': 844,\n",
       " 'College': 845,\n",
       " 'Start': 846,\n",
       " 'health': 847,\n",
       " '99': 848,\n",
       " \"b'forum\": 849,\n",
       " 'wikimedia': 850,\n",
       " 'estate': 851,\n",
       " 'angeles': 852,\n",
       " 'authors': 853,\n",
       " 'TCE': 854,\n",
       " 'key': 855,\n",
       " 'venues': 856,\n",
       " 'su': 857,\n",
       " 'track': 858,\n",
       " 'G': 859,\n",
       " 'night': 860,\n",
       " 'chicago': 861,\n",
       " 'louis': 862,\n",
       " 'Hotel': 863,\n",
       " 'red': 864,\n",
       " 'pic': 865,\n",
       " 'tabs': 866,\n",
       " \"b'kansascity\": 867,\n",
       " \"b'torrentreactor\": 868,\n",
       " '61': 869,\n",
       " 'building': 870,\n",
       " '77': 871,\n",
       " 'verification': 872,\n",
       " 'America': 873,\n",
       " 'jersey': 874,\n",
       " 'checkupdate': 875,\n",
       " 'md': 876,\n",
       " 'festival': 877,\n",
       " \"b'examiner\": 878,\n",
       " \"b'guardian\": 879,\n",
       " 'joseph': 880,\n",
       " '81': 881,\n",
       " 'america': 882,\n",
       " 'white': 883,\n",
       " 'nba': 884,\n",
       " 'links': 885,\n",
       " 'submit': 886,\n",
       " \"b'connect\": 887,\n",
       " '67': 888,\n",
       " 'oh': 889,\n",
       " 'airport': 890,\n",
       " \"b'huffingtonpost\": 891,\n",
       " 'portal': 892,\n",
       " 'two': 893,\n",
       " 'section': 894,\n",
       " 'can': 895,\n",
       " 'referrer': 896,\n",
       " 'jr': 897,\n",
       " 'lng': 898,\n",
       " \"b'nme\": 899,\n",
       " '36': 900,\n",
       " 'ViewArticle': 901,\n",
       " 'class': 902,\n",
       " 'air': 903,\n",
       " 'resources': 904,\n",
       " 'district': 905,\n",
       " \"b'findagrave\": 906,\n",
       " 'H': 907,\n",
       " \"b'publicrecords\": 908,\n",
       " '001': 909,\n",
       " 'T': 910,\n",
       " 'royals': 911,\n",
       " 'ATCLID': 912,\n",
       " '2014': 913,\n",
       " 'births': 914,\n",
       " '64': 915,\n",
       " 'songs': 916,\n",
       " 'ihdb': 917,\n",
       " '90': 918,\n",
       " 'memberprofile': 919,\n",
       " 'regId': 920,\n",
       " 'share': 921,\n",
       " '4u': 922,\n",
       " 'Restore': 923,\n",
       " 'stocks': 924,\n",
       " \"b'fandango\": 925,\n",
       " \"b'wordiq\": 926,\n",
       " \"b'yasni\": 927,\n",
       " 'down': 928,\n",
       " 'encyclopedia': 929,\n",
       " 'ch': 930,\n",
       " 'cz': 931,\n",
       " 'cache': 932,\n",
       " 'france': 933,\n",
       " 'back': 934,\n",
       " 'Ohio': 935,\n",
       " 'coach': 936,\n",
       " 'Of': 937,\n",
       " 'long': 938,\n",
       " 'amp': 939,\n",
       " 'maps': 940,\n",
       " 'livejournal': 941,\n",
       " '33': 942,\n",
       " \"b'lead\": 943,\n",
       " 'securelogin': 944,\n",
       " 'Richard': 945,\n",
       " 'itm': 946,\n",
       " 'ma': 947,\n",
       " 'Acess': 948,\n",
       " 'Pierre': 949,\n",
       " 'centre': 950,\n",
       " 'play': 951,\n",
       " 'mb': 952,\n",
       " 'dead': 953,\n",
       " '35': 954,\n",
       " '2013': 955,\n",
       " 'stars': 956,\n",
       " 'FM': 957,\n",
       " 'rgn': 958,\n",
       " 'ua': 959,\n",
       " '97': 960,\n",
       " 'restaurant': 961,\n",
       " 'order': 962,\n",
       " 'cid': 963,\n",
       " 'e2': 964,\n",
       " 'sfgate': 965,\n",
       " 'W': 966,\n",
       " 'ws': 967,\n",
       " 'Tooken': 968,\n",
       " 'staff': 969,\n",
       " 'over': 970,\n",
       " 'bios': 971,\n",
       " 'Login': 972,\n",
       " 'term': 973,\n",
       " 'jack': 974,\n",
       " 'mls': 975,\n",
       " 'idno': 976,\n",
       " 'Grand': 977,\n",
       " '45': 978,\n",
       " 'Michael': 979,\n",
       " 'Route': 980,\n",
       " \"b'search\": 981,\n",
       " 'davis': 982,\n",
       " 'Le': 983,\n",
       " '2Ck': 984,\n",
       " 'adnxs': 985,\n",
       " 'host': 986,\n",
       " 'if': 987,\n",
       " 'apk': 988,\n",
       " '44': 989,\n",
       " 'jason': 990,\n",
       " \"b'acronyms\": 991,\n",
       " '92': 992,\n",
       " 'other': 993,\n",
       " 'Dropbox': 994,\n",
       " 'rock': 995,\n",
       " 'was': 996,\n",
       " 'Louis': 997,\n",
       " \"b'lyrics\": 998,\n",
       " \"b'vimeo\": 999,\n",
       " 'security': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts = tokenizer.word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([(\"b'diaryofagameaddict\", 2),\n",
       "             ('com', 319223),\n",
       "             (\"'\", 859835),\n",
       "             (\"b'espdesign\", 2),\n",
       "             ('au', 5796),\n",
       "             (\"b'iamagameaddict\", 2),\n",
       "             (\"b'kalantzis\", 2),\n",
       "             ('net', 34048),\n",
       "             (\"b'slightlyoffcenter\", 2),\n",
       "             (\"b'toddscarwash\", 2),\n",
       "             (\"b'tubemoviez\", 2),\n",
       "             (\"b'ipl\", 14),\n",
       "             ('hk', 218),\n",
       "             (\"b'crackspider\", 2),\n",
       "             ('us', 8774),\n",
       "             ('toolbar', 30),\n",
       "             ('install', 270),\n",
       "             ('php', 70441),\n",
       "             ('pack', 122),\n",
       "             ('exe', 4390),\n",
       "             (\"b'pos\", 10),\n",
       "             ('kupang', 2),\n",
       "             (\"b'rupor\", 2),\n",
       "             ('info', 11829),\n",
       "             (\"b'svision\", 2),\n",
       "             ('online', 3142),\n",
       "             ('de', 7248),\n",
       "             ('mgfi', 2),\n",
       "             ('administrator', 710),\n",
       "             ('components', 1294),\n",
       "             ('babackup', 2),\n",
       "             ('classes', 232),\n",
       "             ('fx29id1', 2),\n",
       "             ('txt', 1664),\n",
       "             (\"b'officeon\", 2),\n",
       "             ('ch', 606),\n",
       "             ('ma', 594),\n",
       "             ('office', 757),\n",
       "             ('js', 4826),\n",
       "             ('google', 2199),\n",
       "             ('ad', 534),\n",
       "             ('format', 116),\n",
       "             ('728x90', 394),\n",
       "             ('as', 1042),\n",
       "             (\"b'sn\", 6),\n",
       "             ('gzzx', 2),\n",
       "             (\"b'sunlux\", 2),\n",
       "             ('company', 3567),\n",
       "             ('about', 5991),\n",
       "             ('html', 121155),\n",
       "             (\"b'outporn\", 2),\n",
       "             (\"b'timothycopus\", 2),\n",
       "             ('aimoo', 4),\n",
       "             (\"b'xindalawyer\", 2),\n",
       "             (\"b'freeserials\", 4),\n",
       "             ('spb', 46),\n",
       "             ('ru', 6324),\n",
       "             ('key', 652),\n",
       "             ('68703', 2),\n",
       "             ('htm', 47120),\n",
       "             (\"b'deletespyware\", 2),\n",
       "             ('adware', 4),\n",
       "             (\"b'orbowlada\", 2),\n",
       "             ('strefa', 18),\n",
       "             ('pl', 3156),\n",
       "             ('text396', 1),\n",
       "             ('text', 2035),\n",
       "             ('396', 32),\n",
       "             (\"b'ruiyangcn\", 2),\n",
       "             (\"b'zkic\", 2),\n",
       "             (\"b'adserving\", 2),\n",
       "             ('favorit', 2),\n",
       "             ('network', 813),\n",
       "             ('eas', 6),\n",
       "             ('camp', 218),\n",
       "             ('19320', 4),\n",
       "             ('cre', 8),\n",
       "             ('mu', 214),\n",
       "             ('grpid', 10),\n",
       "             ('1738', 10),\n",
       "             ('tag', 3672),\n",
       "             ('id', 20112),\n",
       "             ('618', 12),\n",
       "             ('nums', 2),\n",
       "             ('FGApbjFAAA', 2),\n",
       "             (\"b'cracks\", 2),\n",
       "             ('vg', 26),\n",
       "             ('d1', 42),\n",
       "             (\"b'juicypussyclips\", 2),\n",
       "             (\"b'nuptialimages\", 2),\n",
       "             (\"b'andysgame\", 2),\n",
       "             (\"b'bezproudoff\", 2),\n",
       "             ('cz', 606),\n",
       "             (\"b'ceskarepublika\", 2),\n",
       "             (\"b'hotspot\", 2),\n",
       "             (\"b'gmcjjh\", 2),\n",
       "             ('org', 78181),\n",
       "             ('DHL', 856),\n",
       "             (\"b'nerez\", 2),\n",
       "             ('schodiste', 2),\n",
       "             ('zabradli', 2),\n",
       "             (\"b'nordiccountry\", 2),\n",
       "             (\"b'nowina\", 2),\n",
       "             (\"b'obada\", 2),\n",
       "             ('konstruktiwa', 2),\n",
       "             (\"b'otylkaaotesanek\", 2),\n",
       "             (\"b'pb\", 4),\n",
       "             ('webdesign', 6),\n",
       "             (\"b'pension\", 2),\n",
       "             ('helene', 38),\n",
       "             (\"b'podzemi\", 2),\n",
       "             ('myotis', 2),\n",
       "             (\"b'smrcek\", 2),\n",
       "             (\"b'spekband\", 2),\n",
       "             (\"b'm\", 312),\n",
       "             ('2132', 10),\n",
       "             ('ehgaugysd', 2),\n",
       "             ('zyso', 4),\n",
       "             ('cgi', 6392),\n",
       "             ('18', 7167),\n",
       "             (\"b'webcom\", 2),\n",
       "             ('software', 362),\n",
       "             ('ws', 580),\n",
       "             ('links', 636),\n",
       "             ('153646e8b0a88', 2),\n",
       "             (\"b'worldgymperu\", 2),\n",
       "             (\"b'zgsysz\", 2),\n",
       "             (\"b'oknarai\", 2),\n",
       "             (\"b'realinnovation\", 2),\n",
       "             ('css', 2217),\n",
       "             ('menu', 230),\n",
       "             (\"b'hardcorepornparty\", 2),\n",
       "             (\"b'zous\", 2),\n",
       "             ('szm', 24),\n",
       "             ('sk', 920),\n",
       "             (\"b'noveslovo\", 2),\n",
       "             (\"b'dimsnetwork\", 2),\n",
       "             (\"b'luckyblank\", 2),\n",
       "             (\"b'luckyclean\", 2),\n",
       "             (\"b'luckyclear\", 2),\n",
       "             (\"b'luckyeffect\", 2),\n",
       "             (\"b'luckyhalo\", 2),\n",
       "             (\"b'luckypure\", 2),\n",
       "             (\"b'luckyshine\", 2),\n",
       "             (\"b'luckysuccess\", 2),\n",
       "             (\"b'luckysure\", 2),\n",
       "             (\"b'luckytidy\", 2),\n",
       "             (\"b'nudebeachgalleries\", 2),\n",
       "             (\"b'buffalogoesout\", 2),\n",
       "             (\"b'achren\", 2),\n",
       "             (\"b'associatesexports\", 2),\n",
       "             (\"b'antalya\", 2),\n",
       "             (\"b'conds\", 2),\n",
       "             (\"b'img\", 8),\n",
       "             ('001', 616),\n",
       "             ('business', 1852),\n",
       "             ('qiji', 2),\n",
       "             (\"b'unalbilgisayar\", 2),\n",
       "             (\"b'soundcomputers\", 2),\n",
       "             (\"b't\", 110),\n",
       "             ('sb', 68),\n",
       "             (\"b'hanulsms\", 2),\n",
       "             (\"b'semengineers\", 2),\n",
       "             (\"b'srslogisticts\", 2),\n",
       "             (\"b'tendersource\", 2),\n",
       "             (\"b'traff\", 2),\n",
       "             ('1', 32989),\n",
       "             ('in', 17464),\n",
       "             ('5', 5893),\n",
       "             (\"b'web\", 702),\n",
       "             ('olymp', 6),\n",
       "             (\"b'oprahsearch\", 4),\n",
       "             ('scripts', 348),\n",
       "             ('net19', 1),\n",
       "             ('19', 1773),\n",
       "             ('brez251', 1),\n",
       "             ('brez', 1),\n",
       "             ('251', 98),\n",
       "             (\"b'rl\", 2),\n",
       "             ('8vd', 2),\n",
       "             ('kikul', 2),\n",
       "             ('ci7ka5t2ue', 2),\n",
       "             (\"b'sbnc\", 2),\n",
       "             ('hak', 2),\n",
       "             ('su', 650),\n",
       "             ('spread', 28),\n",
       "             (\"b'somnoy\", 2),\n",
       "             (\"b'incoctel\", 4),\n",
       "             ('cl', 1166),\n",
       "             ('8RHFBgK4', 4),\n",
       "             ('27', 2701),\n",
       "             ('2369455', 2),\n",
       "             ('7', 4567),\n",
       "             (\"b'westlifego\", 4),\n",
       "             ('jquery', 156),\n",
       "             ('3', 8810),\n",
       "             ('2', 16064),\n",
       "             ('min', 104),\n",
       "             (\"b'nadegda\", 2),\n",
       "             ('95', 661),\n",
       "             (\"b'romsigmed\", 2),\n",
       "             ('ro', 1694),\n",
       "             (\"b'spatsz\", 2),\n",
       "             (\"b'svetyivanrilski\", 2),\n",
       "             (\"b'titon\", 2),\n",
       "             (\"b'tophostbg\", 2),\n",
       "             (\"b'vivaweb\", 2),\n",
       "             (\"b'vocational\", 2),\n",
       "             ('training', 296),\n",
       "             (\"b'warco\", 2),\n",
       "             (\"b'bde\", 2),\n",
       "             ('be', 1612),\n",
       "             (\"b'pwvita\", 2),\n",
       "             (\"b'roks\", 2),\n",
       "             ('ua', 586),\n",
       "             (\"b'skgroup\", 2),\n",
       "             ('kiev', 22),\n",
       "             (\"b'tecnocuer\", 2),\n",
       "             (\"b'tk\", 2),\n",
       "             ('gregoric', 2),\n",
       "             ('si', 698),\n",
       "             (\"b'tomalinoalambres\", 2),\n",
       "             ('ar', 988),\n",
       "             (\"b'vipdn\", 2),\n",
       "             ('123', 508),\n",
       "             ('blackapplehost', 2),\n",
       "             (\"b'womenslabour\", 2),\n",
       "             (\"b'wroclawski\", 2),\n",
       "             (\"b'xoomer\", 18),\n",
       "             ('alice', 253),\n",
       "             ('it', 3688),\n",
       "             ('email', 3739),\n",
       "             ('02', 3991),\n",
       "             ('bom', 16),\n",
       "             ('jpg', 1024),\n",
       "             (\"b'propan\", 2),\n",
       "             ('forum', 2442),\n",
       "             ('downloads', 246),\n",
       "             (\"b'firehouse\", 18),\n",
       "             ('651', 18),\n",
       "             ('gallery', 2648),\n",
       "             ('images', 6455),\n",
       "             ('copyright', 194),\n",
       "             (\"b'freewebtown\", 2),\n",
       "             ('atakus', 2),\n",
       "             ('Nokia', 2),\n",
       "             ('BotNetNew', 2),\n",
       "             (\"b'webcashmaker\", 2),\n",
       "             ('v2', 150),\n",
       "             ('members', 662),\n",
       "             ('trade', 258),\n",
       "             ('traffic', 208),\n",
       "             (\"b'stormpages\", 26),\n",
       "             ('script', 170),\n",
       "             ('PHP', 24),\n",
       "             ('master', 184),\n",
       "             ('psy', 12),\n",
       "             ('ping', 8),\n",
       "             ('diantara', 2),\n",
       "             ('BOT', 2),\n",
       "             (\"b'spykit\", 2),\n",
       "             ('110mb', 26),\n",
       "             ('tools', 168),\n",
       "             (\"b'sentrol\", 2),\n",
       "             ('kampret', 2),\n",
       "             (\"b'kjbbc\", 2),\n",
       "             ('bbs', 162),\n",
       "             ('data', 3009),\n",
       "             ('12072902', 2),\n",
       "             ('28', 2683),\n",
       "             ('inbox', 136),\n",
       "             ('ariefdream', 2),\n",
       "             ('nidec', 2),\n",
       "             ('blewah', 2),\n",
       "             ('bot', 42),\n",
       "             ('hasheo', 6),\n",
       "             ('mil', 416),\n",
       "             ('naoky', 2),\n",
       "             ('ros', 54),\n",
       "             ('VoLcoM', 2),\n",
       "             ('04', 4202),\n",
       "             ('p38r1', 2),\n",
       "             ('aku', 2),\n",
       "             (\"b'torgi\", 4),\n",
       "             ('kz', 116),\n",
       "             ('help', 399),\n",
       "             ('id2', 18),\n",
       "             ('idxx', 2),\n",
       "             (\"b'uriyuri\", 2),\n",
       "             ('skin', 318),\n",
       "             ('zero', 42),\n",
       "             ('vote', 146),\n",
       "             (\"b'usaenterprise\", 2),\n",
       "             (\"b'wigglewoo\", 2),\n",
       "             ('portfolio', 166),\n",
       "             ('contests', 42),\n",
       "             ('contest', 104),\n",
       "             ('006', 42),\n",
       "             ('png', 1032),\n",
       "             (\"b'xorgwebs\", 2),\n",
       "             ('webs', 308),\n",
       "             ('stx', 136),\n",
       "             (\"b'plengeh\", 2),\n",
       "             ('wen', 12),\n",
       "             (\"b'wahyufian\", 2),\n",
       "             ('zoomshare', 2),\n",
       "             ('files', 3596),\n",
       "             (\"b'hospedar\", 2),\n",
       "             ('xpg', 12),\n",
       "             ('br', 6010),\n",
       "             ('nome', 10),\n",
       "             (\"b'dl\", 340),\n",
       "             ('heima8', 1),\n",
       "             ('heima', 1),\n",
       "             ('8', 5914),\n",
       "             ('pv', 80),\n",
       "             ('dl', 158),\n",
       "             ('adid', 20),\n",
       "             ('20132', 2),\n",
       "             ('sid', 830),\n",
       "             ('0211', 4),\n",
       "             (\"b'update\", 82),\n",
       "             ('51edm', 6),\n",
       "             ('2009072', 4),\n",
       "             ('01', 5786),\n",
       "             ('dll', 512),\n",
       "             ('kdg', 4),\n",
       "             (\"b'xiruz\", 2),\n",
       "             ('kit', 146),\n",
       "             ('mola', 2),\n",
       "             (\"b'wfoto\", 2),\n",
       "             ('front', 159),\n",
       "             ('fotos', 32),\n",
       "             (\"b'ska\", 2),\n",
       "             ('energia', 4),\n",
       "             ('download', 1765),\n",
       "             ('imer', 2),\n",
       "             ('up', 1384),\n",
       "             (\"b'obyz\", 2),\n",
       "             ('webproxytest', 2),\n",
       "             (\"b'callingcardsinstantly\", 2),\n",
       "             ('webalizer', 26),\n",
       "             ('050709wareza', 6),\n",
       "             ('crack', 52),\n",
       "             ('17', 1810),\n",
       "             ('keygen', 22),\n",
       "             ('serial', 132),\n",
       "             (\"b'dawnframing\", 2),\n",
       "             (\"b'free\", 150),\n",
       "             ('crochet', 12),\n",
       "             ('pattern', 18),\n",
       "             (\"b'js\", 4),\n",
       "             ('tongji', 8),\n",
       "             ('linezing', 2),\n",
       "             ('1189582', 2),\n",
       "             (\"b'oiluk\", 2),\n",
       "             ('cache', 604),\n",
       "             ('94afbfb2f291e0bf253fcf222e9d238e', 2),\n",
       "             ('180836f9b956ab9d91a50f9add968699', 2),\n",
       "             (\"b'adgallery\", 2),\n",
       "             ('whitehousedrugpolicy', 2),\n",
       "             ('gov', 6164),\n",
       "             ('Miley', 4),\n",
       "             ('Cyrus', 8),\n",
       "             ('Nude', 18),\n",
       "             ('default', 1847),\n",
       "             ('aspx', 21244),\n",
       "             (\"b'vvvic\", 2),\n",
       "             (\"b'sportsulsan\", 2),\n",
       "             ('co', 14700),\n",
       "             ('kr', 438),\n",
       "             ('poll', 182),\n",
       "             ('aipi', 2),\n",
       "             (\"b'papamamandoudouetmoi\", 2),\n",
       "             (\"b'hst\", 4),\n",
       "             ('33', 599),\n",
       "             ('splius', 2),\n",
       "             ('lt', 208),\n",
       "             ('080', 129),\n",
       "             (\"b'tabex\", 2),\n",
       "             ('sopharma', 2),\n",
       "             ('bg', 220),\n",
       "             (\"b'professionalblackbook\", 2),\n",
       "             ('b', 24546),\n",
       "             ('0koryu0', 2),\n",
       "             ('easter', 28),\n",
       "             ('ne', 182),\n",
       "             ('jp', 418),\n",
       "             (\"b'whitesports\", 2),\n",
       "             (\"b'typeofmarijuana\", 2),\n",
       "             (\"b'trafficgrowth\", 2),\n",
       "             (\"b'thcvaporizer\", 2),\n",
       "             (\"b'roorbong\", 2),\n",
       "             (\"b'thcextractor\", 2),\n",
       "             (\"b'purethc\", 2),\n",
       "             (\"b'potvaporizer\", 2),\n",
       "             (\"b'portablevaporizer\", 2),\n",
       "             (\"b'cannabispicture\", 2),\n",
       "             (\"b'cannabislyric\", 2),\n",
       "             (\"b'dp\", 6),\n",
       "             ('medien', 2),\n",
       "             ('eu', 1562),\n",
       "             (\"b'juedische\", 2),\n",
       "             ('kammerphilharmonie', 2),\n",
       "             (\"b'utopia\", 2),\n",
       "             ('muenchen', 12),\n",
       "             (\"b'vernoblisk\", 2),\n",
       "             (\"b'vural\", 2),\n",
       "             ('electronic', 82),\n",
       "             (\"b'purplehorses\", 2),\n",
       "             ('page', 8789),\n",
       "             ('bleach', 26),\n",
       "             ('244', 132),\n",
       "             (\"b'wildsap\", 2),\n",
       "             ('kkk', 20),\n",
       "             ('episodes', 279),\n",
       "             (\"b'ohiomm\", 4),\n",
       "             ('vosta', 2),\n",
       "             (\"b'saturnleague\", 2),\n",
       "             ('mxbb', 2),\n",
       "             ('english', 1102),\n",
       "             ('sub', 300),\n",
       "             (\"b'be\", 100),\n",
       "             ('funk', 56),\n",
       "             (\"b'revistaelite\", 4),\n",
       "             ('topic', 8008),\n",
       "             (\"b'wrestlingexposed\", 2),\n",
       "             ('faq', 181),\n",
       "             ('t', 6254),\n",
       "             ('raw', 158),\n",
       "             (\"b'santacruzsuspension\", 2),\n",
       "             ('j', 1544),\n",
       "             ('episode', 358),\n",
       "             ('245', 126),\n",
       "             (\"b'sitepalace\", 4),\n",
       "             ('w0rmreaper', 2),\n",
       "             ('NoVaC', 2),\n",
       "             ('jpeg', 12),\n",
       "             (\"b'doctor\", 6),\n",
       "             ('alex', 400),\n",
       "             ('SetupDrAlex', 2),\n",
       "             (\"b'cznshuya\", 2),\n",
       "             ('ivnet', 2),\n",
       "             (\"b'tpt\", 4),\n",
       "             ('edu', 14746),\n",
       "             (\"b'inlinea\", 8),\n",
       "             ('uk', 11866),\n",
       "             ('suspended', 40),\n",
       "             ('adnep', 4),\n",
       "             ('simple', 254),\n",
       "             ('tahitian', 2),\n",
       "             (\"b'downloads\", 44),\n",
       "             ('whatsapp', 36),\n",
       "             ('for', 5908),\n",
       "             ('samsung', 64),\n",
       "             (\"b'websalesusa\", 2),\n",
       "             ('ken', 196),\n",
       "             (\"b'rempko\", 2),\n",
       "             ('kontakt', 4),\n",
       "             (\"b'secondome\", 2),\n",
       "             ('sora', 50),\n",
       "             ('margherita', 52),\n",
       "             (\"b'reishus\", 2),\n",
       "             ('sys', 122),\n",
       "             ('action', 1690),\n",
       "             ('fbgen', 2),\n",
       "             ('mode', 358),\n",
       "             ('s', 10636),\n",
       "             ('age', 522),\n",
       "             ('193', 309),\n",
       "             ('a', 10788),\n",
       "             ('18634595', 2),\n",
       "             ('v', 19262),\n",
       "             ('82', 546),\n",
       "             ('crc', 8),\n",
       "             ('669', 25),\n",
       "             ('ie', 1540),\n",
       "             ('6', 4715),\n",
       "             ('0', 8597),\n",
       "             ('2900', 2),\n",
       "             ('2180', 8),\n",
       "             (\"b'sexzoznamka\", 2),\n",
       "             ('lightbox', 42),\n",
       "             ('r', 2176),\n",
       "             ('tasks', 6),\n",
       "             ('AC', 52),\n",
       "             (\"b'a\", 342),\n",
       "             ('update', 1846),\n",
       "             ('2010022', 6),\n",
       "             ('md5', 8),\n",
       "             ('ab2676ca2190bc21abcba6e5f5b3b2a7', 2),\n",
       "             (\"b'bravetools\", 2),\n",
       "             ('en', 14590),\n",
       "             ('mytools', 2),\n",
       "             (\"b'vette\", 2),\n",
       "             ('porno', 44),\n",
       "             ('nl', 1304),\n",
       "             (\"b'obkom\", 2),\n",
       "             ('bancodes', 2),\n",
       "             ('rotator', 2),\n",
       "             ('place', 458),\n",
       "             ('indexfoot', 2),\n",
       "             (\"b'wkmg\", 2),\n",
       "             ('lib', 763),\n",
       "             (\"b'blacknite\", 2),\n",
       "             ('cracking', 4),\n",
       "             ('Pelite', 2),\n",
       "             ('EXE', 4),\n",
       "             (\"b'bargainracks\", 2),\n",
       "             ('img', 1345),\n",
       "             ('common', 374),\n",
       "             ('1x2', 4),\n",
       "             ('gif', 348),\n",
       "             (\"b'pokachi\", 2),\n",
       "             (\"b'pride\", 16),\n",
       "             ('u', 996),\n",
       "             ('bike', 140),\n",
       "             ('2006', 1746),\n",
       "             ('09', 5512),\n",
       "             ('30', 1729),\n",
       "             ('akkymtlator', 2),\n",
       "             ('2007', 2848),\n",
       "             ('06', 4431),\n",
       "             ('23', 1706),\n",
       "             ('tolkacha', 2),\n",
       "             ('07', 4311),\n",
       "             ('doroga', 2),\n",
       "             ('smerti', 2),\n",
       "             ('byzapimoto', 2),\n",
       "             ('motorcycle', 98),\n",
       "             ('suzuki', 10),\n",
       "             ('vozdeniye', 2),\n",
       "             ('sell', 102),\n",
       "             ('honda', 96),\n",
       "             ('steed', 4),\n",
       "             ('400', 115),\n",
       "             ('1996', 377),\n",
       "             ('vfr', 2),\n",
       "             ('400r', 2),\n",
       "             ('nc30', 2),\n",
       "             (\"b'quotidiennokoue\", 6),\n",
       "             ('cat', 1252),\n",
       "             ('p', 10735),\n",
       "             ('558', 25),\n",
       "             (\"b'safety\", 8),\n",
       "             ('amw', 4),\n",
       "             ('family', 1510),\n",
       "             ('ask', 969),\n",
       "             ('john', 2469),\n",
       "             ('walsh', 58),\n",
       "             ('how', 1088),\n",
       "             ('can', 631),\n",
       "             ('i', 4245),\n",
       "             ('tell', 46),\n",
       "             ('if', 572),\n",
       "             ('child', 158),\n",
       "             ('has', 406),\n",
       "             ('been', 96),\n",
       "             ('abused', 10),\n",
       "             ('home', 3997),\n",
       "             ('stop', 142),\n",
       "             ('domestic', 54),\n",
       "             ('violence', 50),\n",
       "             ('before', 134),\n",
       "             ('starts', 52),\n",
       "             (\"b'wmserver\", 2),\n",
       "             ('sgcg', 2),\n",
       "             (\"b'wp\", 38),\n",
       "             ('9', 4020),\n",
       "             (\"b'sanseracingteam\", 4),\n",
       "             ('wordpress', 4518),\n",
       "             ('128', 158),\n",
       "             (\"b'sonnoli\", 2),\n",
       "             (\"b'stirparts\", 2),\n",
       "             (\"b'tiergestuetzt\", 2),\n",
       "             (\"b'pic\", 6),\n",
       "             ('starsarabian', 2),\n",
       "             (\"b'angolotesti\", 6),\n",
       "             ('J', 886),\n",
       "             ('testi', 12),\n",
       "             ('canzoni', 8),\n",
       "             ('jovanotti', 2),\n",
       "             ('168', 267),\n",
       "             ('testo', 74),\n",
       "             ('canzone', 8),\n",
       "             ('chissa', 2),\n",
       "             ('se', 712),\n",
       "             ('stai', 2),\n",
       "             ('dormendo', 2),\n",
       "             ('9566', 4),\n",
       "             (\"b'w\", 276),\n",
       "             ('612', 24),\n",
       "             ('nb', 68),\n",
       "             ('host', 573),\n",
       "             ('127', 282),\n",
       "             ('bins', 280),\n",
       "             ('int', 173),\n",
       "             ('kr3', 2),\n",
       "             ('znp', 2),\n",
       "             ('fxp', 8),\n",
       "             ('384bd820008ee37f030b3e65bca6e8a1a65beab33574f567a23b0a987ca83e6544e3e645',\n",
       "              2),\n",
       "             (\"b'q\", 46),\n",
       "             ('28840', 2),\n",
       "             ('tp', 220),\n",
       "             ('map', 832),\n",
       "             ('16', 1965),\n",
       "             ('5936289861', 2),\n",
       "             ('f351e362768cf97e7b45e0648647f26c6d6750fb2298af91238cf9c815a461',\n",
       "              2),\n",
       "             ('4988', 2),\n",
       "             ('np', 74),\n",
       "             ('pkz', 4),\n",
       "             ('affid', 8),\n",
       "             ('NP', 18),\n",
       "             ('0104', 6),\n",
       "             ('85c26940bd074d9ebe8290842bca496331374b71c3b8806954f77f9', 2),\n",
       "             (\"b'z\", 50),\n",
       "             ('32538', 4),\n",
       "             ('2ac11c971204a16811817c725e04d68a44f9d4987c472f66eb08d0', 2),\n",
       "             (\"b'afa\", 2),\n",
       "             ('15', 2017),\n",
       "             ('media', 2418),\n",
       "             ('videoxxx', 6),\n",
       "             ('avi', 514),\n",
       "             (\"b'rsiuk\", 2),\n",
       "             ('cinch', 2),\n",
       "             ('index', 34064),\n",
       "             (\"b'fgawegwr\", 2),\n",
       "             ('chez', 34),\n",
       "             ('1273471091', 1),\n",
       "             ('12734710', 1),\n",
       "             ('91', 1857),\n",
       "             (\"b'montezuma\", 2),\n",
       "             ('72548', 2),\n",
       "             ('sn', 68),\n",
       "             ('64850', 2),\n",
       "             (\"b'allxscan\", 2),\n",
       "             ('tk', 460),\n",
       "             ('ddt', 4),\n",
       "             ('load', 101),\n",
       "             ('f', 2650),\n",
       "             ('e', 3552),\n",
       "             ('4', 9554),\n",
       "             (\"b'pornstarss\", 2),\n",
       "             ('ntk', 2),\n",
       "             ('ID', 1994),\n",
       "             ('105828', 2),\n",
       "             (\"b'helesouurusa\", 4),\n",
       "             ('cjb', 20),\n",
       "             ('land', 278),\n",
       "             ('video', 4086),\n",
       "             ('l', 4210),\n",
       "             ('52', 485),\n",
       "             ('n', 6882),\n",
       "             ('my', 1244),\n",
       "             ('loli', 6),\n",
       "             ('mike', 704),\n",
       "             ('path', 192),\n",
       "             ('tmb', 4),\n",
       "             ('31', 1377),\n",
       "             ('rat', 54),\n",
       "             ('rating5', 1),\n",
       "             ('61545', 2),\n",
       "             ('rating', 63),\n",
       "             (\"b'luwyou\", 2),\n",
       "             ('photos', 3315),\n",
       "             ('onescan', 2),\n",
       "             ('setupa', 2),\n",
       "             ('onescansetup', 2),\n",
       "             (\"b'sudcom\", 4),\n",
       "             ('tmp', 512),\n",
       "             ('source', 912),\n",
       "             ('pdf', 974),\n",
       "             (\"b'scdsfdfgdr\", 2),\n",
       "             ('12', 5195),\n",
       "             ('go', 4390),\n",
       "             ('afid', 60),\n",
       "             ('51', 691),\n",
       "             (\"b'scaner\", 18),\n",
       "             ('do', 1488),\n",
       "             ('file', 2958),\n",
       "             ('figy', 2),\n",
       "             (\"b'ns\", 152),\n",
       "             ('2ns1', 4),\n",
       "             ('test', 432),\n",
       "             ('or', 804),\n",
       "             (\"b'exsexytop\", 4),\n",
       "             ('www', 2988),\n",
       "             ('sboom', 2),\n",
       "             ('96', 480),\n",
       "             ('sbite', 2),\n",
       "             ('tfeed', 2),\n",
       "             (\"b'linkforme\", 4),\n",
       "             ('tgame', 2),\n",
       "             ('sdee', 2),\n",
       "             ('fill', 38),\n",
       "             (\"b'internet\", 30),\n",
       "             ('bb', 278),\n",
       "             (\"b'textsex\", 4),\n",
       "             ('str', 39),\n",
       "             (\"b'live\", 80),\n",
       "             ('dir', 2676),\n",
       "             (\"b'mbrdot\", 4),\n",
       "             (\"b'zyxyfy\", 2),\n",
       "             ('ner', 2),\n",
       "             (\"b'sexyster\", 4),\n",
       "             ('lo', 184),\n",
       "             (\"b'fkhfgfg\", 8),\n",
       "             ('ftpgrabber', 2),\n",
       "             ('okergrabber', 2),\n",
       "             ('domain', 504),\n",
       "             (\"b'unlim\", 2),\n",
       "             ('app', 1580),\n",
       "             (\"b'new\", 514),\n",
       "             ('address', 316),\n",
       "             ('80', 2123),\n",
       "             (\"b'gameangel\", 2),\n",
       "             ('System', 94),\n",
       "             (\"b'vvps\", 2),\n",
       "             ('44', 570),\n",
       "             ('mothersdarlingcross', 2),\n",
       "             (\"b'beldiplomcom\", 4),\n",
       "             ('75', 552),\n",
       "             ('com1', 3),\n",
       "             ('true', 1032),\n",
       "             ('loading', 275),\n",
       "             ('spl', 22),\n",
       "             ('mdac', 6),\n",
       "             (\"b'url\", 58),\n",
       "             ('cameralist', 2),\n",
       "             ('136', 103),\n",
       "             (\"b'site\", 58),\n",
       "             ('checksite', 2),\n",
       "             ('144', 200),\n",
       "             (\"b'downloaddirect\", 2),\n",
       "             ('vlc', 5),\n",
       "             ('player', 4248),\n",
       "             ('2567', 8),\n",
       "             (\"b'kcta\", 4),\n",
       "             ('json', 54),\n",
       "             (\"b'spris\", 2),\n",
       "             ('log', 685),\n",
       "             ('softdriver', 2),\n",
       "             ('90', 612),\n",
       "             (\"b'orkut\", 12),\n",
       "             ('krovatka', 2),\n",
       "             ('imagem', 2),\n",
       "             ('542454', 2),\n",
       "             (\"b'faq\", 2),\n",
       "             ('candrive', 2),\n",
       "             (\"b'job\", 32),\n",
       "             ('compuse', 2),\n",
       "             (\"b'hosting\", 94),\n",
       "             ('controlnext', 2),\n",
       "             ('controlid1', 2),\n",
       "             ('controlid', 2),\n",
       "             ('156', 159),\n",
       "             ('controlpin', 2),\n",
       "             ('controlpr', 2),\n",
       "             (\"b'image\", 48),\n",
       "             ('circul', 2),\n",
       "             ('companybuild', 2),\n",
       "             (\"b'lab\", 12),\n",
       "             ('cntest', 2),\n",
       "             (\"b'bookofkisl\", 2),\n",
       "             ('album', 4188),\n",
       "             (\"b'infoweb\", 2),\n",
       "             ('coolinfo', 2),\n",
       "             (\"b'alissonluis\", 2),\n",
       "             ('musico', 2),\n",
       "             ('sites', 342),\n",
       "             ('uol', 18),\n",
       "             ('mar', 208),\n",
       "             (\"b'skiholidays\", 2),\n",
       "             ('4beginners', 4),\n",
       "             ('subtraction', 2),\n",
       "             ('scorpio', 4),\n",
       "             ('male', 116),\n",
       "             ('and', 13254),\n",
       "             ('virgo', 2),\n",
       "             ('female', 228),\n",
       "             ('compatiblity', 2),\n",
       "             (\"b'patrickhickey\", 2),\n",
       "             ('concertina', 2),\n",
       "             ('free', 1636),\n",
       "             ('short', 304),\n",
       "             ('skits', 4),\n",
       "             ('hindi', 274),\n",
       "             ('independence', 38),\n",
       "             ('day', 1047),\n",
       "             (\"b'rolemodelstreetteam\", 2),\n",
       "             ('invasioncrew', 2),\n",
       "             ('raazuc', 2),\n",
       "             ('Dossier', 2),\n",
       "             ('For', 304),\n",
       "             ('M', 1000),\n",
       "             (\"b'hy\", 2),\n",
       "             ('brasil', 24),\n",
       "             ('mhwang', 6),\n",
       "             (\"b'marx\", 2),\n",
       "             ('brothers', 210),\n",
       "             (\"b'networkmedical\", 2),\n",
       "             ('defeating', 4),\n",
       "             ('innova', 2),\n",
       "             ('champion', 204),\n",
       "             ('discs', 26),\n",
       "             ('inc', 2027),\n",
       "             ('raven', 8),\n",
       "             (\"b'wallpapers\", 12),\n",
       "             (\"b'rat\", 4),\n",
       "             ('on', 4776),\n",
       "             ('subway', 32),\n",
       "             (\"b'dowdenphotography\", 2),\n",
       "             ('ps', 108),\n",
       "             ('wy', 42),\n",
       "             ('template', 246),\n",
       "             ('printable', 86),\n",
       "             ('brain', 122),\n",
       "             ('cap', 152),\n",
       "             ('teaching', 34),\n",
       "             ('anatomy', 20),\n",
       "             (\"b'seet\", 2),\n",
       "             ('10', 9042),\n",
       "             ('jino', 2),\n",
       "             (\"b'vkont\", 2),\n",
       "             ('bos', 20),\n",
       "             (\"b'download\", 176),\n",
       "             ('207', 178),\n",
       "             ('mediafire', 106),\n",
       "             ('2ezaemp68lyg', 2),\n",
       "             ('fe8lc6kqa1f06n1', 2),\n",
       "             ('Grand', 576),\n",
       "             ('Theft', 6),\n",
       "             ('Modification', 4),\n",
       "             ('zip', 1328),\n",
       "             ('downf468', 101),\n",
       "             ('downf', 101),\n",
       "             ('468', 116),\n",
       "             ('25', 2452),\n",
       "             ('3299664', 2),\n",
       "             ('manual', 126),\n",
       "             ('xc3', 684),\n",
       "             ('xa1sico', 2),\n",
       "             ('windows', 124),\n",
       "             ('movie', 2920),\n",
       "             ('maker', 52),\n",
       "             (\"b'widestep\", 2),\n",
       "             ('qk', 6),\n",
       "             (\"b'casamama\", 2),\n",
       "             (\"b'seoholding\", 6),\n",
       "             ('13', 2222),\n",
       "             ('overblog', 4),\n",
       "             (\"b'seonetwizard\", 2),\n",
       "             ('usg', 38),\n",
       "             ('AFQjCNGS', 2),\n",
       "             ('7Xe0yilVQ6lGj3Oroonf7', 2),\n",
       "             ('gfhg', 2),\n",
       "             (\"b'makohela\", 2),\n",
       "             ('kingofthelamers', 2),\n",
       "             ('jar', 74),\n",
       "             (\"b'crackzone\", 2),\n",
       "             ('Super', 138),\n",
       "             ('Mp', 2),\n",
       "             ('Download', 406),\n",
       "             ('Version', 102),\n",
       "             ('keys', 100),\n",
       "             ('gen', 218),\n",
       "             ('bee3afe71a', 1),\n",
       "             ('bee', 26),\n",
       "             ('3afe71a', 1),\n",
       "             ('boardhost', 8),\n",
       "             (\"b'infra\", 2),\n",
       "             ('by', 3754),\n",
       "             ('conflq', 2),\n",
       "             (\"b'elocumjobs\", 2),\n",
       "             ('sql', 28),\n",
       "             (\"b'nobodyspeakstruth\", 2),\n",
       "             ('narod', 12),\n",
       "             ('upload', 1752),\n",
       "             ('main', 2526),\n",
       "             (\"b'remorcicomerciale\", 2),\n",
       "             ('hyb', 2),\n",
       "             ('7w2u', 2),\n",
       "             (\"b'negociosdasha\", 2),\n",
       "             ('uqa', 2),\n",
       "             ('5q2p', 2),\n",
       "             (\"b'eldiariodeguadalajara\", 2),\n",
       "             ('153c5f', 2),\n",
       "             (\"b'paracadutismolucca\", 2),\n",
       "             ('fe7041', 2),\n",
       "             (\"b'aintdoinshit\", 2),\n",
       "             (\"b'cswilliamsburg\", 2),\n",
       "             ('site', 2020),\n",
       "             (\"b'bj\", 6),\n",
       "             ('myimg', 2),\n",
       "             ('IMG1507', 1),\n",
       "             ('IMG', 29),\n",
       "             ('1507', 9),\n",
       "             (\"b'pamoran\", 4),\n",
       "             ('got', 90),\n",
       "             (\"b'police\", 18),\n",
       "             ('11', 8065),\n",
       "             ('provenprotection', 2),\n",
       "             ('1284cf325cf33aa48aeb29aee89b3473', 2),\n",
       "             (\"b'qbike\", 6),\n",
       "             ('lidn', 2),\n",
       "             (\"b'serraikizimi\", 2),\n",
       "             ('gr', 1006),\n",
       "             ('akAYd', 2),\n",
       "             ('6dn', 2),\n",
       "             ('0zz0', 4),\n",
       "             ('2012', 790),\n",
       "             ('05', 4319),\n",
       "             ('394995639', 1),\n",
       "             ('3949956', 1),\n",
       "             ('39', 503),\n",
       "             ('00', 901),\n",
       "             ('464591666', 1),\n",
       "             ('4645916', 1),\n",
       "             ('66', 725),\n",
       "             (\"b'metrocuadro\", 2),\n",
       "             ('ve', 182),\n",
       "             ('coolest', 6),\n",
       "             ('2013googledocs', 14),\n",
       "             (\"b'petpleasers\", 2),\n",
       "             ('ca', 23552),\n",
       "             ('templates', 990),\n",
       "             ('rhuk', 4),\n",
       "             ('milkyway', 4),\n",
       "             ('red', 648),\n",
       "             ('sll', 2),\n",
       "             (\"b'dimenal\", 4),\n",
       "             ('cUEDN', 2),\n",
       "             ('4w2', 2),\n",
       "             ('883', 22),\n",
       "             ('lid', 94),\n",
       "             ('2267', 6),\n",
       "             ('elq', 12),\n",
       "             ('11f7b1b5179f45b09737bdf10d0fe61f', 10),\n",
       "             ('HHv', 2),\n",
       "             ('0oxBP', 2),\n",
       "             ('2298', 4),\n",
       "             (\"b'miespaciopilates\", 2),\n",
       "             ('7Fy2FzNg', 2),\n",
       "             (\"b'puenteaereo\", 6),\n",
       "             ('fHA', 4),\n",
       "             ('5c5iw', 4),\n",
       "             ('2231', 6),\n",
       "             ('2270', 6),\n",
       "             ('KE3pt5Ye', 2),\n",
       "             ('2328', 6),\n",
       "             (\"b'serciudadano\", 2),\n",
       "             ('wp', 16294),\n",
       "             ('content', 9536),\n",
       "             ('uploads', 778),\n",
       "             ('report', 689),\n",
       "             (\"b'zjjlf\", 2),\n",
       "             ('croukwexdbyerr', 2),\n",
       "             (\"b'panazan\", 4),\n",
       "             ('libraries', 1116),\n",
       "             ('pattemplate', 24),\n",
       "             ('patTemplate', 24),\n",
       "             ('Modifier', 8),\n",
       "             ('HTML', 226),\n",
       "             ('im', 194),\n",
       "             ('o', 1430),\n",
       "             ('z', 675),\n",
       "             ('3pingo', 4),\n",
       "             ('cfg', 24),\n",
       "             ('bin', 2977),\n",
       "             ('gate', 2081),\n",
       "             (\"b'two\", 304),\n",
       "             ('of', 19580),\n",
       "             ('at', 4386),\n",
       "             ('W', 582),\n",
       "             (\"b'poffet\", 2),\n",
       "             ('mail', 1365),\n",
       "             ('updatesdns', 2),\n",
       "             ('static', 409),\n",
       "             ('htmls', 10),\n",
       "             (\"b'topdecornegocios\", 2),\n",
       "             ('EiqyDBxS', 2),\n",
       "             (\"b'win\", 18),\n",
       "             ('2150', 12),\n",
       "             ('vs', 2286),\n",
       "             ('easily', 14),\n",
       "             ('f49oj2TB', 2),\n",
       "             (\"b'stailapoza\", 2),\n",
       "             ('9kxmzBou', 2),\n",
       "             ('vein', 2),\n",
       "             (\"b'qualityindustrialcoatings\", 2),\n",
       "             ('wM19L5ST', 2),\n",
       "             (\"b'avrakougioumtzi\", 2),\n",
       "             ('r3qd8wqB', 2),\n",
       "             ('s4x', 2),\n",
       "             ('s2x', 2),\n",
       "             (\"b'wetjane\", 2),\n",
       "             ('x10', 8),\n",
       "             ('mx', 746),\n",
       "             (\"b'storgas\", 2),\n",
       "             ('rs', 294),\n",
       "             ...])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum 420464\n",
      "indexs 378418\n"
     ]
    }
   ],
   "source": [
    "#对数据进行分割\n",
    "#先打乱\n",
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "labels = train_y[indices]\n",
    "\n",
    "train_sample = data.shape[0]  - (data.shape[0] // 10)\n",
    "print('sum',data.shape[0])\n",
    "print('indexs',train_sample)\n",
    "\n",
    "x_train = data[:train_sample]\n",
    "y_train = labels[:train_sample]\n",
    "x_val = data[train_sample:]\n",
    "y_val = labels[train_sample:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(378418, 15)\n",
      "(42046, 15)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3493,  445,  445,  148, 7205,  148, 7205, 7567, 7567,  315,   42,\n",
       "         315,   42,    1,    1],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,  733,\n",
       "           2,  733,    1,    1],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,  233,    2,  233,\n",
       "          37,   37,    1,    1],\n",
       "       [1061,    2, 1061,  110,  110, 1853,  502,  502, 3213,    1, 1853,\n",
       "         502,  502, 3213,    1],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,  913,    2,  913,\n",
       "         256,    1,  256,    1],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    2,  623,  623,\n",
       "         658,    1,  658,    1],\n",
       "       [7406,   33, 3581, 7406, 3130,  170,    3,    1,   33, 3581, 7406,\n",
       "        3130,  170,    3,    1],\n",
       "       [1638, 1638,  198,  198,  375,  375,   87,  562,    2,   87,  562,\n",
       "         138,    1,  138,    1],\n",
       "       [   0,    0,   27,    2,   27,   61,   61,  117, 5096, 2873,  117,\n",
       "        5096, 2873,    1,    1],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    2,    1,    1]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "GLOVE_DIR = 'D:\\Jupyter\\glove.6B'\n",
    "embeddings_index = {}\n",
    "with open(os.path.join(GLOVE_DIR, 'glove.6B.50d.txt'), encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 50\n",
    "embedding_matrix = np.zeros((len(word_index)+1, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 版本一：使用Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, 15, 50)            21962300  \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 64)                29440     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 21,993,853\n",
      "Trainable params: 31,553\n",
      "Non-trainable params: 21,962,300\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "\n",
    "rate_drop_lstm = 0.2\n",
    "\n",
    "#【max_words单词， embedding_dims单词对应的维度向量】\n",
    "embedding_dim = 100\n",
    "\n",
    "\n",
    "# 定义模型\n",
    "#【样本，每个样本100单词，每个单词100维度】\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Flatten, Dense, Bidirectional, LSTM\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(word_index)+1,\n",
    "                    EMBEDDING_DIM,\n",
    "                    input_length=maxlen,\n",
    "                    weights=[embedding_matrix],\n",
    "                    trainable=False,\n",
    "                   ))#构建词嵌入，每个单词\n",
    "# model.add(layers.Conv1D(32, 5, activation='relu'))\n",
    "# model.add(layers.MaxPooling1D(3))\n",
    "model.add(LSTM(64, dropout=rate_drop_lstm, recurrent_dropout=rate_drop_lstm))\n",
    "#model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu'))#负责单词之间的练习和语义\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 378418 samples, validate on 42046 samples\n",
      "Epoch 1/10\n",
      "378418/378418 [==============================] - 348s 919us/step - loss: 0.2146 - acc: 0.9177 - val_loss: 0.1560 - val_acc: 0.9415\n",
      "Epoch 2/10\n",
      "378418/378418 [==============================] - 343s 906us/step - loss: 0.1719 - acc: 0.9360 - val_loss: 0.1491 - val_acc: 0.9462\n",
      "Epoch 3/10\n",
      "378418/378418 [==============================] - 338s 893us/step - loss: 0.1633 - acc: 0.9403 - val_loss: 0.1434 - val_acc: 0.9484\n",
      "Epoch 4/10\n",
      "378418/378418 [==============================] - 338s 892us/step - loss: 0.1602 - acc: 0.9420 - val_loss: 0.1381 - val_acc: 0.9503\n",
      "Epoch 5/10\n",
      "378418/378418 [==============================] - 335s 885us/step - loss: 0.1585 - acc: 0.9424 - val_loss: 0.1398 - val_acc: 0.9499\n",
      "Epoch 6/10\n",
      "378418/378418 [==============================] - 337s 890us/step - loss: 0.1593 - acc: 0.9426 - val_loss: 0.1368 - val_acc: 0.9511\n",
      "Epoch 7/10\n",
      "378418/378418 [==============================] - 332s 876us/step - loss: 0.1592 - acc: 0.9426 - val_loss: 0.1373 - val_acc: 0.9515\n",
      "Epoch 8/10\n",
      "378418/378418 [==============================] - 338s 893us/step - loss: 0.1605 - acc: 0.9429 - val_loss: 0.1388 - val_acc: 0.9516\n",
      "Epoch 9/10\n",
      "378418/378418 [==============================] - 353s 932us/step - loss: 0.1624 - acc: 0.9425 - val_loss: 0.1378 - val_acc: 0.9525\n",
      "Epoch 10/10\n",
      "378418/378418 [==============================] - 361s 955us/step - loss: 0.1649 - acc: 0.9422 - val_loss: 0.1409 - val_acc: 0.9512\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['acc'])\n",
    "history = model.fit(x_train, y_train,\n",
    "                   epochs=10,\n",
    "                   batch_size=32,\n",
    "                   validation_data=(x_val, y_val),\n",
    "                   #callbacks=callback_list,\n",
    "                    verbose =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('used_Glove.h5')\n",
    "model.save_weights('used_Glove_weight.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 版本二：自训练Embedding，效果不好\n",
    "如果解决又取max_words又能导入embedding_weight就好了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, 15, 50)            500000    \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 64)                29440     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 531,553\n",
      "Trainable params: 531,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "\n",
    "rate_drop_lstm = 0.2\n",
    "\n",
    "#【max_words单词， embedding_dims单词对应的维度向量】\n",
    "embedding_dim = 100\n",
    "\n",
    "\n",
    "# 定义模型\n",
    "#【样本，每个样本100单词，每个单词100维度】\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Flatten, Dense, Bidirectional, LSTM\n",
    "\n",
    "model_ = Sequential()\n",
    "model_.add(Embedding(max_words,\n",
    "                    EMBEDDING_DIM,\n",
    "                    input_length=maxlen,\n",
    "                   ))#构建词嵌入，每个单词\n",
    "# model.add(layers.Conv1D(32, 5, activation='relu'))\n",
    "# model.add(layers.MaxPooling1D(3))\n",
    "model_.add(LSTM(64, dropout=rate_drop_lstm, recurrent_dropout=rate_drop_lstm))\n",
    "#model.add(Flatten())\n",
    "model_.add(Dense(32, activation='relu'))#负责单词之间的练习和语义\n",
    "model_.add(Dense(1, activation='sigmoid'))\n",
    "model_.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 378418 samples, validate on 42046 samples\n",
      "Epoch 1/10\n",
      "325952/378418 [========================>.....] - ETA: 46s - loss: 0.4738 - acc: 0.8195"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m-------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-221-39c3f1e0600f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m                    \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m                    \u001b[1;31m#callbacks=callback_list,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m                     verbose =1)\n\u001b[0m",
      "\u001b[1;32mF:\\Anaconda\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    958\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    959\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 960\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m    961\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    962\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[1;32mF:\\Anaconda\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1646\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1647\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1648\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1649\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1650\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mF:\\Anaconda\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1213\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1214\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2350\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2351\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2352\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2353\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2354\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    875\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 877\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    878\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1098\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1100\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1101\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1270\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1272\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1273\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1274\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1276\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1277\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1278\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1279\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1280\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1261\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1263\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1265\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1348\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['acc'])\n",
    "history = model.fit(x_train, y_train,\n",
    "                   epochs=10,\n",
    "                   batch_size=32,\n",
    "                   validation_data=(x_val, y_val),\n",
    "                   #callbacks=callback_list,\n",
    "                    verbose =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 版本三 ： 加入Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 15, 50)\n",
      "WARNING:tensorflow:From F:\\Anaconda\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1208: calling reduce_max (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From F:\\Anaconda\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1242: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From F:\\Anaconda\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1344: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:25: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "F:\\Anaconda\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\legacy\\layers.py:458: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 15, 50)            21962300  \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 64)                29440     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 21,993,853\n",
      "Trainable params: 31,553\n",
      "Non-trainable params: 21,962,300\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras.layers import merge\n",
    "from keras.models import *\n",
    "from keras.layers import Embedding, Flatten, Dense, Bidirectional, LSTM\n",
    "from keras.layers.core import *\n",
    "#[batch_size, ax_words]\n",
    "#【max_words单词， embedding_dims单词对应的维度向量】\n",
    "embedding_dim = 50\n",
    "rate_drop_lstm = 0.2\n",
    "SINGLE_ATTENTION_VECTOR = True\n",
    "\n",
    "def attention_3d_block(inputs):\n",
    "    # inputs.shape = (batch_size, time_steps15, input_dim50)\n",
    "    print(inputs.shape)\n",
    "    input_dim = int(inputs.shape[2])\n",
    "    time_steps = int(inputs.shape[1])\n",
    "    \n",
    "    a = Permute((2, 1))(inputs)\n",
    "    #a = Reshape((input_dim, TIME_STEPS))(a) # this line is not useful. It's just to know which dimension is what.\n",
    "    a = Dense(time_steps, activation='softmax')(a)\n",
    "    if SINGLE_ATTENTION_VECTOR:\n",
    "        a = Lambda(lambda x: K.mean(x, axis=1), name='dim_reduction')(a)\n",
    "        a = RepeatVector(input_dim)(a)\n",
    "    a_probs = Permute((2, 1), name='attention_vec')(a)\n",
    "    output_attention_mul = merge([inputs, a_probs], name='attention_mul', mode='mul')\n",
    "    return output_attention_mul\n",
    "\n",
    "\n",
    "\n",
    "# 定义模型\n",
    "#【样本，每个样本100单词，每个单词100维度】\n",
    "# EMBEDDING_DIM = 50\n",
    "# maxlen = 15\n",
    "\n",
    "inputs = Input(shape=(maxlen,))\n",
    "# 层输入【samples， maxlen】\n",
    "# 层输出【samples， maxlen， dims】\n",
    "emb = Embedding(len(word_index)+1,\n",
    "                    EMBEDDING_DIM,\n",
    "                    input_length=maxlen,\n",
    "                    weights=[embedding_matrix],\n",
    "                    trainable=False,\n",
    "                   )#构建词嵌入，每个单词\n",
    "emb = emb(inputs)\n",
    "attention_mul = attention_3d_block(emb)\n",
    "# model.add(layers.Conv1D(32, 5, activation='relu'))\n",
    "# model.add(layers.MaxPooling1D(3))\n",
    "x = LSTM(64, dropout=rate_drop_lstm, recurrent_dropout=rate_drop_lstm)(emb)\n",
    "#model.add(Flatten())\n",
    "x = Dense(32, activation='relu')(x)#负责单词之间的练习和语义\n",
    "output = Dense(1, activation='sigmoid')(x)\n",
    "model = Model(inputs, output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import TensorBoard, ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "\n",
    "\n",
    "class Callback(object):\n",
    "    def __init__(self, model_name):\n",
    "        self.model_name = model_name\n",
    "        self.log_dir = \"{}_logs/\".format(self.model_name)\n",
    "        self.model_dir = \"{}_models/\".format(self.model_name)\n",
    "\n",
    "    def get_tensorboard(self):#是一个可视化的展示器\n",
    "        tensorboard_callback = TensorBoard(log_dir=self.log_dir, write_grads=True,\n",
    "                                           histogram_freq=0, write_images=True)\n",
    "        return tensorboard_callback\n",
    "\n",
    "    def get_early_stop(self, patience):#当监测值不再改善时，该回调函数将中止训练\n",
    "        early_stop = EarlyStopping('val_acc', patience=patience)\n",
    "        return early_stop\n",
    "\n",
    "    def get_readuce_lr(self, factor, patience):#学习率衰减\n",
    "        return ReduceLROnPlateau(monitor='val_acc', factor=factor, patience=patience)\n",
    "\n",
    "    def get_model_ckpt(self):#在每个epoch后保存模型\n",
    "        model_names = self.model_dir + '.{epoch:02d}-{val_acc:.4f}.h5'\n",
    "        model_checkpoint = ModelCheckpoint(model_names, monitor='val_acc', verbose=1, save_best_only=True)\n",
    "        return model_checkpoint\n",
    "\n",
    "callbacks = Callback('LSTM')\n",
    "tensorboard = callbacks.get_tensorboard()\n",
    "early_stop = callbacks.get_early_stop(5)\n",
    "readuce_lr = callbacks.get_readuce_lr(factor=0.5, patience=50 // 4)\n",
    "model_ckpt = callbacks.get_model_ckpt()\n",
    "callback_list = [tensorboard, early_stop, readuce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 378418 samples, validate on 42046 samples\n",
      "Epoch 1/10\n",
      " 23456/378418 [>.............................] - ETA: 6:56 - loss: 0.3343 - acc: 0.8666"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m-------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-39c3f1e0600f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m                    \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m                    \u001b[1;31m#callbacks=callback_list,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m                     verbose =1)\n\u001b[0m",
      "\u001b[1;32mF:\\Anaconda\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1646\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1647\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1648\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1649\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1650\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mF:\\Anaconda\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1213\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1214\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2350\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2351\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2352\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2353\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2354\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    875\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 877\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    878\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1098\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1100\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1101\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1270\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1272\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1273\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1274\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1276\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1277\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1278\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1279\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1280\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1261\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1263\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1265\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1348\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['acc'])\n",
    "history = model.fit(x_train, y_train,\n",
    "                   epochs=10,\n",
    "                   batch_size=32,\n",
    "                   validation_data=(x_val, y_val),\n",
    "                   #callbacks=callback_list,\n",
    "                    verbose =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('used_Attention_LSTM.h5')\n",
    "model.save_weights('used_attention_LSTM_weight.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 对比实验，使用RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From F:\\Anaconda\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1242: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 15, 50)            21962300  \n",
      "_________________________________________________________________\n",
      "simple_rnn_1 (SimpleRNN)     (None, 64)                7360      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 21,971,773\n",
      "Trainable params: 9,473\n",
      "Non-trainable params: 21,962,300\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "\n",
    "rate_drop_lstm = 0.2\n",
    "\n",
    "#【max_words单词， embedding_dims单词对应的维度向量】\n",
    "embedding_dim = 100\n",
    "\n",
    "\n",
    "# 定义模型\n",
    "#【样本，每个样本100单词，每个单词100维度】\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Flatten, Dense, Bidirectional, LSTM\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(word_index)+1,\n",
    "                    EMBEDDING_DIM,\n",
    "                    input_length=maxlen,\n",
    "                    weights=[embedding_matrix],\n",
    "                    trainable=False,\n",
    "                   ))#构建词嵌入，每个单词\n",
    "# model.add(layers.Conv1D(32, 5, activation='relu'))\n",
    "# model.add(layers.MaxPooling1D(3))\n",
    "model.add(layers.SimpleRNN(64))\n",
    "#model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu'))#负责单词之间的练习和语义\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From F:\\Anaconda\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1344: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "Train on 378418 samples, validate on 42046 samples\n",
      "Epoch 1/4\n",
      "378418/378418 [==============================] - 140s 369us/step - loss: 0.2185 - acc: 0.9165 - val_loss: 0.1929 - val_acc: 0.9317\n",
      "Epoch 2/4\n",
      "378418/378418 [==============================] - 136s 361us/step - loss: 0.1799 - acc: 0.9336 - val_loss: 0.1732 - val_acc: 0.9371\n",
      "Epoch 3/4\n",
      "378418/378418 [==============================] - 135s 357us/step - loss: 0.1701 - acc: 0.9384 - val_loss: 0.1787 - val_acc: 0.9390\n",
      "Epoch 4/4\n",
      "378418/378418 [==============================] - 143s 377us/step - loss: 0.1665 - acc: 0.9401 - val_loss: 0.1764 - val_acc: 0.9399\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['acc'])\n",
    "history = model.fit(x_train, y_train,\n",
    "                   epochs=4,\n",
    "                   batch_size=32,\n",
    "                   validation_data=(x_val, y_val),\n",
    "                   #callbacks=callback_list,\n",
    "                    verbose =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 对比实验，使用GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 15, 50)            21962300  \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 64)                22080     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 21,986,493\n",
      "Trainable params: 24,193\n",
      "Non-trainable params: 21,962,300\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "\n",
    "rate_drop_lstm = 0.2\n",
    "\n",
    "#【max_words单词， embedding_dims单词对应的维度向量】\n",
    "embedding_dim = 100\n",
    "\n",
    "\n",
    "# 定义模型\n",
    "#【样本，每个样本100单词，每个单词100维度】\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Flatten, Dense, Bidirectional, LSTM\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(word_index)+1,\n",
    "                    EMBEDDING_DIM,\n",
    "                    input_length=maxlen,\n",
    "                    weights=[embedding_matrix],\n",
    "                    trainable=False,\n",
    "                   ))#构建词嵌入，每个单词\n",
    "# model.add(layers.Conv1D(32, 5, activation='relu'))\n",
    "# model.add(layers.MaxPooling1D(3))\n",
    "model.add(layers.GRU(64))\n",
    "#model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu'))#负责单词之间的练习和语义\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 378418 samples, validate on 42046 samples\n",
      "Epoch 1/4\n",
      "378418/378418 [==============================] - 329s 871us/step - loss: 0.1824 - acc: 0.9310 - val_loss: 0.1564 - val_acc: 0.9423\n",
      "Epoch 2/4\n",
      "378418/378418 [==============================] - 247s 653us/step - loss: 0.1416 - acc: 0.9480 - val_loss: 0.1423 - val_acc: 0.9491\n",
      "Epoch 3/4\n",
      "378418/378418 [==============================] - 236s 623us/step - loss: 0.1315 - acc: 0.9521 - val_loss: 0.1343 - val_acc: 0.9520\n",
      "Epoch 4/4\n",
      "378418/378418 [==============================] - 252s 666us/step - loss: 0.1270 - acc: 0.9537 - val_loss: 0.1326 - val_acc: 0.9530\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['acc'])\n",
    "history = model.fit(x_train, y_train,\n",
    "                   epochs=4,\n",
    "                   batch_size=32,\n",
    "                   validation_data=(x_val, y_val),\n",
    "                   #callbacks=callback_list,\n",
    "                    verbose =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 对比实验，使用双向LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 15, 50)            21962300  \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 128)               58880     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 22,025,341\n",
      "Trainable params: 63,041\n",
      "Non-trainable params: 21,962,300\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "\n",
    "rate_drop_lstm = 0.2\n",
    "\n",
    "#【max_words单词， embedding_dims单词对应的维度向量】\n",
    "embedding_dim = 100\n",
    "\n",
    "\n",
    "# 定义模型\n",
    "#【样本，每个样本100单词，每个单词100维度】\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Flatten, Dense, Bidirectional, LSTM\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(word_index)+1,\n",
    "                    EMBEDDING_DIM,\n",
    "                    input_length=maxlen,\n",
    "                    weights=[embedding_matrix],\n",
    "                    trainable=False,\n",
    "                   ))#构建词嵌入，每个单词\n",
    "# model.add(layers.Conv1D(32, 5, activation='relu'))\n",
    "# model.add(layers.MaxPooling1D(3))\n",
    "model.add(layers.Bidirectional(LSTM(64, dropout=rate_drop_lstm, recurrent_dropout=rate_drop_lstm)))\n",
    "#model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu'))#负责单词之间的练习和语义\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 378418 samples, validate on 42046 samples\n",
      "Epoch 1/4\n",
      "378418/378418 [==============================] - 863s 2ms/step - loss: 0.2079 - acc: 0.9210 - val_loss: 0.1565 - val_acc: 0.9408\n",
      "Epoch 2/4\n",
      "378418/378418 [==============================] - 740s 2ms/step - loss: 0.1672 - acc: 0.9382 - val_loss: 0.1498 - val_acc: 0.9457\n",
      "Epoch 3/4\n",
      "378418/378418 [==============================] - 626s 2ms/step - loss: 0.1583 - acc: 0.9422 - val_loss: 0.1438 - val_acc: 0.9487\n",
      "Epoch 4/4\n",
      "378418/378418 [==============================] - 595s 2ms/step - loss: 0.1546 - acc: 0.9438 - val_loss: 0.1366 - val_acc: 0.9505\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['acc'])\n",
    "history = model.fit(x_train, y_train,\n",
    "                   epochs=4,\n",
    "                   batch_size=32,\n",
    "                   validation_data=(x_val, y_val),\n",
    "                   #callbacks=callback_list,\n",
    "                    verbose =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-gpu",
   "language": "python",
   "name": "tensorflow-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
